= Unlocking Data with Generative AI and RAG
:icons: font

Enhance generative AI systems by integrating internal data with large language models using RAG

Keith Bourne

== Part 1 – Introduction to Retrieval-Augmented Generation (RAG)

=== Chapter 2: Code Lab – An Entire RAG Pipeline

==== 2.5. Indexing

The document outlines the indexing stage of data processing, particularly focusing on web loading, data pre-processing, and vectorization for use in a generative AI application. The steps involved include:

1. **Web Loading and Crawling**: This step involves fetching data from a specified web page using the **WebBaseLoader** class from the **langchain_community document_loaders** module, which pulls in necessary content based on specified CSS classes.

2. **Data Pre-processing and Splitting**: After collecting the documents, the content is split into manageable chunks using a text splitter, specifically the **SemanticChunker**. This chunker preserves the semantic context of the text rather than splitting it arbitrarily, which is important for maintaining coherence in the data.

3. **Embedding and Indexing**: The chunks are then converted into vector embeddings using **OpenAIEmbeddings** and stored in a Chroma vector database. This process involves creating a vector store from the split documents and generating mathematical representations (embeddings) of the content.

4. **Retriever Creation**: A retriever mechanism is established to facilitate vector similarity searches within the vector database, enabling efficient retrieval of relevant documents based on user queries.

The document encourages experimentation with different web pages, text splitters, and embedding methods to understand their effects on data processing and retrieval outcomes. Overall, it serves as a foundational guide for setting up data indexing in a generative AI context.
