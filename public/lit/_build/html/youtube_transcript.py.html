<!DOCTYPE html>

<html lang="en" data-content_root="./">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>YouTube Transcript &#8212; lit  documentation</title>
    <link rel="stylesheet" type="text/css" href="_static/pygments.css?v=5ecbeea2" />
    <link rel="stylesheet" type="text/css" href="_static/basic.css?v=b08954a9" />
    <link rel="stylesheet" type="text/css" href="_static/alabaster.css?v=27fed22d" />
    <script src="_static/documentation_options.js?v=5929fcd5"></script>
    <script src="_static/doctools.js?v=9bcbadda"></script>
    <script src="_static/sphinx_highlight.js?v=dc90522c"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="prev" title="Albums" href="albums.py.html" />
   
  <link rel="stylesheet" href="_static/custom.css" type="text/css" />
  

  
  

  </head><body>
  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          

          <div class="body" role="main">
            
  <section id="youtube-transcript">
<h1><a class="toc-backref" href="#id1" role="doc-backlink">YouTube Transcript</a><a class="headerlink" href="#youtube-transcript" title="Link to this heading">¶</a></h1>
<nav class="contents" id="contents">
<p class="topic-title">Contents</p>
<ul class="simple">
<li><p><a class="reference internal" href="#youtube-transcript" id="id1">YouTube Transcript</a></p>
<ul>
<li><p><a class="reference internal" href="#multimodel" id="id2">MultiModel</a></p></li>
</ul>
</li>
</ul>
</nav>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">streamlit</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">st</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">os</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">typing</span><span class="w"> </span><span class="kn">import</span> <span class="n">Optional</span><span class="p">,</span> <span class="n">Dict</span><span class="p">,</span> <span class="n">Any</span>

<span class="kn">from</span><span class="w"> </span><span class="nn">youtube_transcript_api</span><span class="w"> </span><span class="kn">import</span> <span class="n">YouTubeTranscriptApi</span><span class="p">,</span> <span class="n">TranscriptsDisabled</span><span class="p">,</span> <span class="n">NoTranscriptFound</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">openai</span><span class="w"> </span><span class="kn">import</span> <span class="n">OpenAI</span>
</pre></div>
</div>
<p>Prints a stylized banner to the console when the application starts.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">st</span><span class="o">.</span><span class="n">set_page_config</span><span class="p">(</span>
    <span class="n">page_title</span><span class="o">=</span><span class="s2">&quot;You-T&quot;</span>
<span class="p">)</span>

<span class="nd">@st</span><span class="o">.</span><span class="n">cache_data</span>
<span class="k">def</span><span class="w"> </span><span class="nf">print_banner</span><span class="p">():</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;&quot;&quot;</span>
<span class="s2">             )</span>
<span class="s2">          ( /(                  *   )</span>
<span class="s2">          )</span><span class="se">\\</span><span class="s2">())       (       ` )  /(</span>
<span class="s2">         ((_)</span><span class="se">\\</span><span class="s2">  (    ))</span><span class="se">\\</span><span class="s2">  ___  ( )(_))</span>
<span class="s2">        __ ((_) )</span><span class="se">\\</span><span class="s2">  /((_)|___|(_(_())</span>
<span class="s2">        </span><span class="se">\\</span><span class="s2"> </span><span class="se">\\</span><span class="s2"> / /((_)(_))(      |_   _|</span>
<span class="s2">         </span><span class="se">\\</span><span class="s2"> V // _ </span><span class="se">\\</span><span class="s2">| || |       | |</span>
<span class="s2">          |_| </span><span class="se">\\</span><span class="s2">___/ </span><span class="se">\\</span><span class="s2">_,_|       |_|</span>
<span class="s2">        &quot;&quot;&quot;</span><span class="p">)</span>
    <span class="k">return</span> <span class="mi">1</span>

<span class="n">print_banner</span><span class="p">()</span>
</pre></div>
</div>
<p>Get transcript from YouTube URL</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">youtube_url</span> <span class="o">=</span> <span class="n">st</span><span class="o">.</span><span class="n">text_input</span><span class="p">(</span><span class="s2">&quot;YouTube URL&quot;</span><span class="p">)</span>
<span class="n">lang</span> <span class="o">=</span> <span class="n">st</span><span class="o">.</span><span class="n">radio</span><span class="p">(</span><span class="s2">&quot;Language&quot;</span><span class="p">,</span> <span class="p">[</span><span class="s2">&quot;ru&quot;</span><span class="p">,</span><span class="s2">&quot;en&quot;</span><span class="p">,</span><span class="s2">&quot;by&quot;</span><span class="p">],</span> <span class="n">horizontal</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="n">transcript_file</span> <span class="o">=</span> <span class="s2">&quot;transcript.txt&quot;</span>

<span class="k">def</span><span class="w"> </span><span class="nf">transcript_as_text</span><span class="p">(</span><span class="n">url</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">lang</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s1">&#39;en&#39;</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Returns one plain‑text string containing the caption lines.</span>
<span class="sd">    Falls back to auto‑generated captions if no manual track exists.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">video_id</span> <span class="o">=</span> <span class="n">url</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">&quot;v=&quot;</span><span class="p">)[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">&quot;&amp;&quot;</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>

    <span class="k">try</span><span class="p">:</span>
        <span class="c1"># This tries manual captions first, then auto‑generated.</span>
        <span class="n">transcript</span> <span class="o">=</span> <span class="n">YouTubeTranscriptApi</span><span class="o">.</span><span class="n">get_transcript</span><span class="p">(</span><span class="n">video_id</span><span class="p">,</span> <span class="n">languages</span><span class="o">=</span><span class="p">[</span><span class="n">lang</span><span class="p">])</span>
        <span class="k">return</span> <span class="s2">&quot; &quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">chunk</span><span class="p">[</span><span class="s1">&#39;text&#39;</span><span class="p">]</span> <span class="k">for</span> <span class="n">chunk</span> <span class="ow">in</span> <span class="n">transcript</span><span class="p">)</span>
    <span class="k">except</span> <span class="n">TranscriptsDisabled</span><span class="p">:</span>
        <span class="k">return</span> <span class="s2">&quot;[Captions are disabled on this video.]&quot;</span>
    <span class="k">except</span> <span class="n">NoTranscriptFound</span><span class="p">:</span>
        <span class="k">return</span> <span class="s2">&quot;[No transcript available in the requested language.]&quot;</span>

<span class="c1"># Truncate text to max len</span>
<span class="k">def</span><span class="w"> </span><span class="nf">max_len</span><span class="p">(</span><span class="n">text</span><span class="p">,</span> <span class="n">k</span><span class="p">):</span>
    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">text</span><span class="p">)</span> <span class="o">&lt;=</span> <span class="n">k</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">text</span>
    <span class="k">return</span> <span class="n">text</span><span class="p">[:</span><span class="n">k</span><span class="p">]</span> <span class="o">+</span> <span class="s1">&#39;...&#39;</span>

<span class="k">if</span> <span class="n">st</span><span class="o">.</span><span class="n">button</span><span class="p">(</span><span class="s2">&quot;Save Transcript&quot;</span><span class="p">,</span> <span class="n">use_container_width</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
    <span class="n">transcript</span> <span class="o">=</span> <span class="n">transcript_as_text</span><span class="p">(</span><span class="n">youtube_url</span><span class="p">,</span> <span class="n">lang</span><span class="p">)</span>
    <span class="n">st</span><span class="o">.</span><span class="n">text_area</span><span class="p">(</span><span class="s2">&quot;Transcript&quot;</span><span class="p">,</span> <span class="n">transcript</span><span class="p">,</span> <span class="n">height</span><span class="o">=</span><span class="mi">300</span><span class="p">)</span>

    <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">transcript_file</span><span class="p">,</span> <span class="s1">&#39;w&#39;</span><span class="p">,</span> <span class="n">encoding</span><span class="o">=</span><span class="s1">&#39;utf-8&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">file</span><span class="p">:</span>
        <span class="n">file</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="n">transcript</span><span class="p">)</span>

    <span class="n">st</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Transcript saved: `</span><span class="si">{</span><span class="n">transcript_file</span><span class="si">}</span><span class="s2">`&quot;</span><span class="p">)</span>
</pre></div>
</div>
<p>Get trunscript summary</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">prompt_summary</span> <span class="o">=</span> <span class="s2">&quot;&quot;&quot;</span>
<span class="s2">Тебе будет передана расшифровка видео.</span>
<span class="s2">Твоя задача: подготовить ёмкое резюме.</span>
<span class="s2">&quot;&quot;&quot;</span>

<span class="n">llm_prices</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s2">&quot;gemini-2.5-flash-preview-05-20&quot;</span><span class="p">:</span> <span class="mf">0.0</span><span class="p">,</span>
    <span class="s2">&quot;gemini-2.0-flash&quot;</span><span class="p">:</span> <span class="mf">0.0</span><span class="p">,</span>
    <span class="s2">&quot;gemma-3-27b-it&quot;</span><span class="p">:</span> <span class="mf">0.0</span><span class="p">,</span>
    <span class="s2">&quot;gpt-4.1-mini&quot;</span><span class="p">:</span> <span class="mf">0.4</span><span class="p">,</span>
    <span class="s2">&quot;gpt-4.1-nano&quot;</span><span class="p">:</span> <span class="mf">0.1</span><span class="p">,</span>
    <span class="s2">&quot;gpt-4.1&quot;</span><span class="p">:</span> <span class="mf">2.0</span><span class="p">,</span>
    <span class="s2">&quot;gpt-4o-mini&quot;</span><span class="p">:</span> <span class="mf">0.15</span><span class="p">,</span>
    <span class="s2">&quot;o4-mini&quot;</span><span class="p">:</span> <span class="mf">1.10</span><span class="p">,</span>
    <span class="s2">&quot;o3-mini&quot;</span><span class="p">:</span> <span class="mf">1.10</span><span class="p">,</span>
    <span class="s2">&quot;gpt-4o&quot;</span><span class="p">:</span> <span class="mf">2.5</span><span class="p">,</span>
    <span class="s2">&quot;o1&quot;</span><span class="p">:</span> <span class="mf">15.0</span><span class="p">,</span>
<span class="p">}</span>
<span class="n">llm_models</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">llm_prices</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span>
</pre></div>
</div>
<section id="multimodel">
<h2><a class="toc-backref" href="#id2" role="doc-backlink">MultiModel</a><a class="headerlink" href="#multimodel" title="Link to this heading">¶</a></h2>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">class</span><span class="w"> </span><span class="nc">MultiModel</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Wrapper for multiple LLM APIs (OpenAI, Gemini, Gemma).</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">llm_model</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">llm_temperature</span> <span class="o">=</span> <span class="mf">0.1</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">llm_model</span> <span class="o">=</span> <span class="n">llm_model</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">llm_temperature</span> <span class="o">=</span> <span class="n">llm_temperature</span>

        <span class="n">vendor</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_vendor</span><span class="p">(</span><span class="n">llm_model</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">vendor</span> <span class="o">==</span> <span class="s2">&quot;google&quot;</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">client</span> <span class="o">=</span> <span class="n">OpenAI</span><span class="p">(</span>
                <span class="n">api_key</span><span class="o">=</span><span class="n">os</span><span class="o">.</span><span class="n">getenv</span><span class="p">(</span><span class="s2">&quot;GEMINI_API_KEY&quot;</span><span class="p">),</span>
                <span class="n">base_url</span><span class="o">=</span><span class="s2">&quot;https://generativelanguage.googleapis.com/v1beta/openai/&quot;</span>
            <span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">client</span> <span class="o">=</span> <span class="n">OpenAI</span><span class="p">()</span>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">_get_vendor</span><span class="p">(</span><span class="n">llm_model</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Determines the vendor based on the model name.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">llm_model</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span><span class="o">.</span><span class="n">startswith</span><span class="p">((</span><span class="s2">&quot;gemini&quot;</span><span class="p">,</span> <span class="s2">&quot;gemma&quot;</span><span class="p">)):</span>
            <span class="k">return</span> <span class="s2">&quot;google&quot;</span>
        <span class="k">return</span> <span class="s2">&quot;openai&quot;</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_call_gpt</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">prompt</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">text</span><span class="p">:</span> <span class="nb">str</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Calls a GPT-like model with standard message format and temperature.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">messages</span> <span class="o">=</span> <span class="p">[</span>
            <span class="p">{</span><span class="s2">&quot;role&quot;</span><span class="p">:</span> <span class="s2">&quot;system&quot;</span><span class="p">,</span> <span class="s2">&quot;content&quot;</span><span class="p">:</span> <span class="n">prompt</span><span class="p">},</span>
            <span class="p">{</span><span class="s2">&quot;role&quot;</span><span class="p">:</span> <span class="s2">&quot;user&quot;</span><span class="p">,</span> <span class="s2">&quot;content&quot;</span><span class="p">:</span> <span class="n">text</span><span class="p">},</span>
        <span class="p">]</span>
        <span class="n">response</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">client</span><span class="o">.</span><span class="n">chat</span><span class="o">.</span><span class="n">completions</span><span class="o">.</span><span class="n">create</span><span class="p">(</span>
            <span class="n">model</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">llm_model</span><span class="p">,</span>
            <span class="n">messages</span><span class="o">=</span><span class="n">messages</span><span class="p">,</span>
            <span class="n">temperature</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">llm_temperature</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="k">return</span> <span class="n">response</span><span class="o">.</span><span class="n">choices</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_call_gemma</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">prompt</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">text</span><span class="p">:</span> <span class="nb">str</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Calls a Gemma model with custom message format and temperature.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">messages</span> <span class="o">=</span> <span class="p">[</span>
            <span class="p">{</span><span class="s2">&quot;role&quot;</span><span class="p">:</span> <span class="s2">&quot;user&quot;</span><span class="p">,</span> <span class="s2">&quot;content&quot;</span><span class="p">:</span> <span class="sa">f</span><span class="s2">&quot;&lt;instructions&gt;</span><span class="si">{</span><span class="n">prompt</span><span class="si">}</span><span class="s2">&lt;/instructions&gt;</span><span class="se">\n</span><span class="s2">&lt;user_input&gt;</span><span class="si">{</span><span class="n">text</span><span class="si">}</span><span class="s2">&lt;/user_input&gt;&quot;</span><span class="p">},</span>
        <span class="p">]</span>
        <span class="n">response</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">client</span><span class="o">.</span><span class="n">chat</span><span class="o">.</span><span class="n">completions</span><span class="o">.</span><span class="n">create</span><span class="p">(</span>
            <span class="n">model</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">llm_model</span><span class="p">,</span>
            <span class="n">messages</span><span class="o">=</span><span class="n">messages</span><span class="p">,</span>
            <span class="n">temperature</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">llm_temperature</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="k">return</span> <span class="n">response</span><span class="o">.</span><span class="n">choices</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_call_o_model</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">prompt</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">text</span><span class="p">:</span> <span class="nb">str</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Calls an &#39;o&#39;-prefixed model with standard message format, no temperature.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">messages</span> <span class="o">=</span> <span class="p">[</span>
            <span class="p">{</span><span class="s2">&quot;role&quot;</span><span class="p">:</span> <span class="s2">&quot;system&quot;</span><span class="p">,</span> <span class="s2">&quot;content&quot;</span><span class="p">:</span> <span class="n">prompt</span><span class="p">},</span>
            <span class="p">{</span><span class="s2">&quot;role&quot;</span><span class="p">:</span> <span class="s2">&quot;user&quot;</span><span class="p">,</span> <span class="s2">&quot;content&quot;</span><span class="p">:</span> <span class="n">text</span><span class="p">},</span>
        <span class="p">]</span>
        <span class="n">response</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">client</span><span class="o">.</span><span class="n">chat</span><span class="o">.</span><span class="n">completions</span><span class="o">.</span><span class="n">create</span><span class="p">(</span>
            <span class="n">model</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">llm_model</span><span class="p">,</span>
            <span class="n">messages</span><span class="o">=</span><span class="n">messages</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="k">return</span> <span class="n">response</span><span class="o">.</span><span class="n">choices</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">call_llm</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">prompt</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">text</span><span class="p">:</span> <span class="nb">str</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Calls the appropriate LLM based on the model name.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">model</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">llm_model</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span>
        <span class="k">if</span> <span class="n">model</span><span class="o">.</span><span class="n">startswith</span><span class="p">((</span><span class="s2">&quot;gemini&quot;</span><span class="p">,</span> <span class="s2">&quot;gpt&quot;</span><span class="p">)):</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_call_gpt</span><span class="p">(</span><span class="n">prompt</span><span class="p">,</span> <span class="n">text</span><span class="p">)</span>
        <span class="k">elif</span> <span class="n">model</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="s2">&quot;gemma&quot;</span><span class="p">):</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_call_gemma</span><span class="p">(</span><span class="n">prompt</span><span class="p">,</span> <span class="n">text</span><span class="p">)</span>
        <span class="k">elif</span> <span class="n">model</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="s2">&quot;o&quot;</span><span class="p">):</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_call_o_model</span><span class="p">(</span><span class="n">prompt</span><span class="p">,</span> <span class="n">text</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Unknown model prefix for: </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">llm_model</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
<p>Select LLM</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">llm_model</span> <span class="o">=</span> <span class="n">st</span><span class="o">.</span><span class="n">selectbox</span><span class="p">(</span><span class="s2">&quot;LLM Model&quot;</span><span class="p">,</span> <span class="n">llm_models</span><span class="p">)</span>

<span class="k">def</span><span class="w"> </span><span class="nf">create_summary</span><span class="p">():</span>
    <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">transcript_file</span><span class="p">,</span> <span class="s1">&#39;r&#39;</span><span class="p">,</span> <span class="n">encoding</span><span class="o">=</span><span class="s1">&#39;utf-8&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">file</span><span class="p">:</span>
        <span class="n">transcript</span> <span class="o">=</span> <span class="n">file</span><span class="o">.</span><span class="n">read</span><span class="p">()</span>

    <span class="n">llm</span> <span class="o">=</span> <span class="n">MultiModel</span><span class="p">(</span><span class="n">llm_model</span><span class="p">)</span>
    <span class="n">summary</span> <span class="o">=</span> <span class="n">llm</span><span class="o">.</span><span class="n">call_llm</span><span class="p">(</span><span class="n">prompt_summary</span><span class="p">,</span> <span class="n">transcript</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">summary</span><span class="o">.</span><span class="n">message</span><span class="o">.</span><span class="n">content</span>
</pre></div>
</div>
<p>Summary button</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">if</span> <span class="n">st</span><span class="o">.</span><span class="n">button</span><span class="p">(</span><span class="s2">&quot;Summary&quot;</span><span class="p">,</span> <span class="n">use_container_width</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
    <span class="n">st</span><span class="o">.</span><span class="n">session_state</span><span class="o">.</span><span class="n">summary</span> <span class="o">=</span> <span class="n">create_summary</span><span class="p">()</span>

<span class="n">st</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="n">st</span><span class="o">.</span><span class="n">session_state</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;summary&quot;</span><span class="p">))</span>
</pre></div>
</div>
</section>
</section>


          </div>
          
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="Main">
        <div class="sphinxsidebarwrapper">
<h1 class="logo"><a href="index.html">lit</a></h1>









<search id="searchbox" style="display: none" role="search">
    <div class="searchformwrapper">
    <form class="search" action="search.html" method="get">
      <input type="text" name="q" aria-labelledby="searchlabel" autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" placeholder="Search"/>
      <input type="submit" value="Go" />
    </form>
    </div>
</search>
<script>document.getElementById('searchbox').style.display = "block"</script><h3>Navigation</h3>
<p class="caption" role="heading"><span class="caption-text">Contents:</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="ai_note.py.html">Note-AI</a></li>
<li class="toctree-l1"><a class="reference internal" href="ai_obsidian.py.html">Obsidian-AI</a></li>
<li class="toctree-l1"><a class="reference internal" href="o_ed.py.html">Obsidian Web Editor</a></li>
<li class="toctree-l1"><a class="reference internal" href="explain_java.py.html">Explain Java</a></li>
<li class="toctree-l1"><a class="reference internal" href="book_lc.py.html">Book Chat (LC)</a></li>
<li class="toctree-l1"><a class="reference internal" href="book_chat.py.html">Book Chat (LI)</a></li>
<li class="toctree-l1"><a class="reference internal" href="o_chat.py.html">Obsidian Chat (LI)</a></li>
<li class="toctree-l1"><a class="reference internal" href="li_extract.py.html">LlamaIndex Extractors</a></li>
<li class="toctree-l1"><a class="reference internal" href="L1_Router_Engine.py.html">Llamaindex Router</a></li>
<li class="toctree-l1"><a class="reference internal" href="udemy.py.html">Udemy</a></li>
<li class="toctree-l1"><a class="reference internal" href="time_intervals.py.html">Time Intervals</a></li>
<li class="toctree-l1"><a class="reference internal" href="md_view.py.html">Markdown Viewer</a></li>
<li class="toctree-l1"><a class="reference internal" href="pan_ui.py.html">Pandoc UI</a></li>
<li class="toctree-l1"><a class="reference internal" href="code_review.py.html">Code Review</a></li>
<li class="toctree-l1"><a class="reference internal" href="doc_note.py.html">Doc-Note</a></li>
<li class="toctree-l1"><a class="reference internal" href="up_file.py.html">Upload File</a></li>
<li class="toctree-l1"><a class="reference internal" href="epub_toc.py.html">EPUB TOC</a></li>
<li class="toctree-l1"><a class="reference internal" href="pom_csv.py.html">POM CSV</a></li>
<li class="toctree-l1"><a class="reference internal" href="exc_yaml.py.html">exc yaml</a></li>
<li class="toctree-l1"><a class="reference internal" href="exc_ui.py.html">exc UI</a></li>
<li class="toctree-l1"><a class="reference internal" href="exc_histo.py.html">exc histo</a></li>
<li class="toctree-l1"><a class="reference internal" href="cmp_folders.py.html">Сравнение папок</a></li>
<li class="toctree-l1"><a class="reference internal" href="adoc_links.py.html">AsciiDoc links</a></li>
<li class="toctree-l1"><a class="reference internal" href="jira_stats.py.html">Jira Stats</a></li>
<li class="toctree-l1"><a class="reference internal" href="grafana_stats.py.html">Grafana Stats</a></li>
<li class="toctree-l1"><a class="reference internal" href="google_search.py.html">Google Search</a></li>
<li class="toctree-l1"><a class="reference internal" href="ollama_chat.py.html">Ollama Chat</a></li>
<li class="toctree-l1"><a class="reference internal" href="cmp_props.py.html">Compare Properties</a></li>
<li class="toctree-l1"><a class="reference internal" href="pi_keys.py.html">Rasp Hotkeys</a></li>
<li class="toctree-l1"><a class="reference internal" href="albums.py.html">Albums</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">YouTube Transcript</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#multimodel">MultiModel</a></li>
</ul>
</li>
</ul>

<div class="relations">
<h3>Related Topics</h3>
<ul>
  <li><a href="index.html">Documentation overview</a><ul>
      <li>Previous: <a href="albums.py.html" title="previous chapter">Albums</a></li>
  </ul></li>
</ul>
</div>








        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="footer">
      &#169;2025, EA.
      
      |
      Powered by 
      <a href="https://slott56.github.io/PyLit-3/_build/html/index.html">PyLit 3.1.1</a>
      &amp; 
      <a href="https://www.sphinx-doc.org/">Sphinx 8.2.3</a>
      &amp; 
      <a href="https://alabaster.readthedocs.io">Alabaster 1.0.0</a>
      
      |
      <a href="_sources/youtube_transcript.py.rst.txt"
          rel="nofollow">Page source</a>
    </div>

    

    
  </body>
</html>