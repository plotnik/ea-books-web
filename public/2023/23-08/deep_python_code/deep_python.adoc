= 23-08 Deep Learning with Python - 2nd Edition
François Chollet
:toc:

== 1 What is deep learning?

=== 1.1 Artificial intelligence, machine learning, and deep learning

The layer's function in processing input data is determined by its _weights_, which are numerical values. Technically, the layer's operation is _parameterized_ by these weights, which can also be referred to as the layer's _parameters_.

_Learning_ in this context involves identifying the proper values for the weights across all layers in a network so that the network accurately associates input examples with their corresponding targets.

To manage the output of a neural network, it's essential to monitor it, which is done through a _loss function_. The loss function evaluates the network's predictions against the desired targets by calculating a distance score, indicating the network's performance on a given example. This function is also known as the _objective function_ or _cost function_.

=== 1.2 Before deep learning - A brief history of machine learning

_Probabilistic modeling_ uses statistical principles for data analysis and is foundational in machine learning. The Naive Bayes algorithm is a well-known example that applies Bayes' theorem with the assumption that all input features are independent. This technique has been in use since before the advent of computers, with its principles dating back to the 18th century. _Logistic regression_ is another related model which, despite its name, is used for classification tasks. It is also an old but still relevant technique, commonly used as an initial approach by data scientists for its simplicity and versatility.

Deep learning has gained popularity not only because of its superior performance on many tasks but also because it simplifies problem-solving by eliminating the need for _feature engineering_. In traditional machine learning methods, called shallow learning, humans had to manually create and fine-tune features from the data for the algorithms to work effectively. Deep learning, however, automates this process by learning all necessary features in a single pass through a multi-layered network structure.

Shallow learning methods like SVMs or decision trees only transform data into one or two layers of representation, which often isn't sufficient for complex problems. Attempting to apply shallow methods in succession to mimic deep learning is inefficient because each layer's optimal representation isn't the same across different model complexities. Deep learning's transformative approach is its ability to _learn multiple layers of representation jointly_. This means that all layers adjust together in response to a single feedback signal, allowing the model to develop increasingly complex and abstract representations through a series of simple transformations across layers.

The two key aspects of how deep learning learns from data are the _incremental development of more complex representations through multiple layers_ and the _joint learning of these representations_, which enables each layer to be refined in coordination with the others. These properties have made deep learning much more effective than previous machine learning methods.

From 2016 to 2020, the machine learning and data science field has been primarily focused on two methodologies: deep learning for perceptual tasks like image classification, and gradient boosted trees for structured data problems. Practitioners use Python libraries such as Scikit-learn, XGBoost, and LightGBM for gradient boosted trees and Keras, often with TensorFlow, for deep learning. Proficiency in these techniques and tools is considered crucial for success in applied machine learning, and they are frequently used in Kaggle competitions.

=== 1.3 Why deep learning - Why now

Deep learning is considered a significant advancement in AI with several properties that make it a robust and long-lasting approach, likely to influence future technologies. These properties include:

1. _Simplicity:_ Deep learning simplifies model building by eliminating the need for feature engineering, allowing for end-to-end training with a limited set of operations.

2. _Scalability:_ It benefits from GPU or TPU parallelization and can handle vast datasets thanks to batch-based training, making it compatible with the ongoing improvements in computational power.

3. _Versatility and Reusability:_ Deep learning models can be continuously updated with new data and repurposed for different tasks, making them adaptable and efficient for various applications, even with smaller datasets.

While deep learning has been prominent for only a few years, its potential is still unfolding with new use cases and improvements. The field saw rapid progress initially, which is now stabilizing into more incremental advancements. Innovations like Transformer-based models in natural language processing have marked significant milestones. As of 2021, deep learning may be entering a phase of more steady and less explosive growth, but significant developments are still anticipated in the coming years. The deployment of deep learning across numerous applications is expected to continue, as its full potential has yet to be fully realized.

== 2 The mathematical building blocks of neural networks

=== 2.1 A first look at a neural network

An overview of a neural network example using Keras, a Python library, to classify handwritten digits from the MNIST dataset. The dataset includes 60,000 training images and 10,000 test images of grayscale digits, each 28x28 pixels. The classification task involves assigning these images to one of ten classes (0-9).

The neural network architecture consists of two densely connected layers. The first layer has 512 units with `ReLU` activation, and the second is a `softmax` layer with 10 units, corresponding to the 10 digit classes. The softmax layer outputs a probability distribution across the classes.

To prepare the model for training, the following steps are taken:

1. Compiling the model with an optimizer (`RMSprop`), a loss function (`sparse_categorical_crossentropy`), and a metric (`accuracy`).
2. Preprocessing the image data by reshaping it into a flat array and normalizing pixel values to the range `[0, 1]`.

The model is trained using the `fit` method on the preprocessed training data for 5 epochs with a batch size of 128. The performance is measured in terms of loss and accuracy on the training data, achieving a high accuracy of 98.9%.

After training, the model can predict class probabilities for new images. For example, when the model predicts the class for a test digit, it outputs a probability distribution, with the highest probability indicating the predicted class.

Evaluating the model on the test set shows an accuracy of 97.8%, which is slightly lower than the training accuracy due to overfitting—a common issue in machine learning where models perform better on training data than on new, unseen data.

The example serves as an introduction to building and training a neural network for digit classification and sets the stage for deeper explanations in subsequent chapters about tensors, tensor operations, and gradient descent. The reader is not expected to understand all details at this point, as the forthcoming chapters will provide a more thorough explanation.

=== 2.2 Data representations for neural networks

A tensor is a container for numerical data, which generalizes the concept of matrices to higher dimensions, known as axes. The following points summarize the key ideas and examples provided about tensors:

- **Scalars (0D tensors)**: A single number, having zero axes (ndim = 0).
- **Vectors (1D tensors)**: An array of numbers, having one axis.
- **Matrices (2D tensors)**: An array of vectors, having two axes (rows and columns).
- **Higher-rank tensors**: Arrays of 2D tensors are 3D tensors, and so on. Deep learning typically involves tensors with 0 to 4 axes, occasionally 5 for video data.

Tensors are characterized by three main attributes:

- **Number of axes (rank)**: The dimensionality or number of axes in a tensor.
- **Shape**: The dimensions the tensor has along each axis.
- **Data type (dtype)**: The type of data stored in the tensor (e.g., float32, uint8).

In the context of machine learning, you often deal with tensors that have specific shapes and meanings, such as:

- **Data batches**: The first axis (axis 0) is usually the samples axis, used for mini-batches in training.
- **Real-world data tensors**: These can include vector data (2D tensors), time series or sequence data (3D), images (4D), and videos (5D).

Specific examples include:

- **Vector data**: Rank-2 tensors with shape `(samples, features)`.
- **Time series data**: Rank-3 tensors with shape `(samples, timesteps, features)`.
- **Image data**: Rank-4 tensors with shape `(samples, height, width, channels)` or `(samples, channels, height, width)`.
- **Video data**: Rank-5 tensors with shape `(samples, frames, height, width, channels)`.

In practice, slicing tensors allows for selecting specific elements, sequences, or regions from these arrays. For instance, to access a portion of an image or a sequence of data points within a time series.

Understanding these tensor operations is crucial for preprocessing and manipulating the data used to train machine learning models, like the example shown where a digit from the MNIST dataset is displayed using Matplotlib, or when taking a specific batch of images from a larger tensor for processing.

