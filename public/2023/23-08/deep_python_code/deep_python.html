<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta name="generator" content="Asciidoctor 2.0.20">
<meta name="author" content="François Chollet">
<title>23-08 Deep Learning with Python - 2nd Edition</title>
<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:300,300italic,400,400italic,600,600italic%7CNoto+Serif:400,400italic,700,700italic%7CDroid+Sans+Mono:400,700">
<style>
/*! Asciidoctor default stylesheet | MIT License | https://asciidoctor.org */
/* Uncomment the following line when using as a custom stylesheet */
/* @import "https://fonts.googleapis.com/css?family=Open+Sans:300,300italic,400,400italic,600,600italic%7CNoto+Serif:400,400italic,700,700italic%7CDroid+Sans+Mono:400,700"; */
html{font-family:sans-serif;-webkit-text-size-adjust:100%}
a{background:none}
a:focus{outline:thin dotted}
a:active,a:hover{outline:0}
h1{font-size:2em;margin:.67em 0}
b,strong{font-weight:bold}
abbr{font-size:.9em}
abbr[title]{cursor:help;border-bottom:1px dotted #dddddf;text-decoration:none}
dfn{font-style:italic}
hr{height:0}
mark{background:#ff0;color:#000}
code,kbd,pre,samp{font-family:monospace;font-size:1em}
pre{white-space:pre-wrap}
q{quotes:"\201C" "\201D" "\2018" "\2019"}
small{font-size:80%}
sub,sup{font-size:75%;line-height:0;position:relative;vertical-align:baseline}
sup{top:-.5em}
sub{bottom:-.25em}
img{border:0}
svg:not(:root){overflow:hidden}
figure{margin:0}
audio,video{display:inline-block}
audio:not([controls]){display:none;height:0}
fieldset{border:1px solid silver;margin:0 2px;padding:.35em .625em .75em}
legend{border:0;padding:0}
button,input,select,textarea{font-family:inherit;font-size:100%;margin:0}
button,input{line-height:normal}
button,select{text-transform:none}
button,html input[type=button],input[type=reset],input[type=submit]{-webkit-appearance:button;cursor:pointer}
button[disabled],html input[disabled]{cursor:default}
input[type=checkbox],input[type=radio]{padding:0}
button::-moz-focus-inner,input::-moz-focus-inner{border:0;padding:0}
textarea{overflow:auto;vertical-align:top}
table{border-collapse:collapse;border-spacing:0}
*,::before,::after{box-sizing:border-box}
html,body{font-size:100%}
body{background:#fff;color:rgba(0,0,0,.8);padding:0;margin:0;font-family:"Noto Serif","DejaVu Serif",serif;line-height:1;position:relative;cursor:auto;-moz-tab-size:4;-o-tab-size:4;tab-size:4;word-wrap:anywhere;-moz-osx-font-smoothing:grayscale;-webkit-font-smoothing:antialiased}
a:hover{cursor:pointer}
img,object,embed{max-width:100%;height:auto}
object,embed{height:100%}
img{-ms-interpolation-mode:bicubic}
.left{float:left!important}
.right{float:right!important}
.text-left{text-align:left!important}
.text-right{text-align:right!important}
.text-center{text-align:center!important}
.text-justify{text-align:justify!important}
.hide{display:none}
img,object,svg{display:inline-block;vertical-align:middle}
textarea{height:auto;min-height:50px}
select{width:100%}
.subheader,.admonitionblock td.content>.title,.audioblock>.title,.exampleblock>.title,.imageblock>.title,.listingblock>.title,.literalblock>.title,.stemblock>.title,.openblock>.title,.paragraph>.title,.quoteblock>.title,table.tableblock>.title,.verseblock>.title,.videoblock>.title,.dlist>.title,.olist>.title,.ulist>.title,.qlist>.title,.hdlist>.title{line-height:1.45;color:#7a2518;font-weight:400;margin-top:0;margin-bottom:.25em}
div,dl,dt,dd,ul,ol,li,h1,h2,h3,#toctitle,.sidebarblock>.content>.title,h4,h5,h6,pre,form,p,blockquote,th,td{margin:0;padding:0}
a{color:#2156a5;text-decoration:underline;line-height:inherit}
a:hover,a:focus{color:#1d4b8f}
a img{border:0}
p{line-height:1.6;margin-bottom:1.25em;text-rendering:optimizeLegibility}
p aside{font-size:.875em;line-height:1.35;font-style:italic}
h1,h2,h3,#toctitle,.sidebarblock>.content>.title,h4,h5,h6{font-family:"Open Sans","DejaVu Sans",sans-serif;font-weight:300;font-style:normal;color:#ba3925;text-rendering:optimizeLegibility;margin-top:1em;margin-bottom:.5em;line-height:1.0125em}
h1 small,h2 small,h3 small,#toctitle small,.sidebarblock>.content>.title small,h4 small,h5 small,h6 small{font-size:60%;color:#e99b8f;line-height:0}
h1{font-size:2.125em}
h2{font-size:1.6875em}
h3,#toctitle,.sidebarblock>.content>.title{font-size:1.375em}
h4,h5{font-size:1.125em}
h6{font-size:1em}
hr{border:solid #dddddf;border-width:1px 0 0;clear:both;margin:1.25em 0 1.1875em}
em,i{font-style:italic;line-height:inherit}
strong,b{font-weight:bold;line-height:inherit}
small{font-size:60%;line-height:inherit}
code{font-family:"Droid Sans Mono","DejaVu Sans Mono",monospace;font-weight:400;color:rgba(0,0,0,.9)}
ul,ol,dl{line-height:1.6;margin-bottom:1.25em;list-style-position:outside;font-family:inherit}
ul,ol{margin-left:1.5em}
ul li ul,ul li ol{margin-left:1.25em;margin-bottom:0}
ul.circle{list-style-type:circle}
ul.disc{list-style-type:disc}
ul.square{list-style-type:square}
ul.circle ul:not([class]),ul.disc ul:not([class]),ul.square ul:not([class]){list-style:inherit}
ol li ul,ol li ol{margin-left:1.25em;margin-bottom:0}
dl dt{margin-bottom:.3125em;font-weight:bold}
dl dd{margin-bottom:1.25em}
blockquote{margin:0 0 1.25em;padding:.5625em 1.25em 0 1.1875em;border-left:1px solid #ddd}
blockquote,blockquote p{line-height:1.6;color:rgba(0,0,0,.85)}
@media screen and (min-width:768px){h1,h2,h3,#toctitle,.sidebarblock>.content>.title,h4,h5,h6{line-height:1.2}
h1{font-size:2.75em}
h2{font-size:2.3125em}
h3,#toctitle,.sidebarblock>.content>.title{font-size:1.6875em}
h4{font-size:1.4375em}}
table{background:#fff;margin-bottom:1.25em;border:1px solid #dedede;word-wrap:normal}
table thead,table tfoot{background:#f7f8f7}
table thead tr th,table thead tr td,table tfoot tr th,table tfoot tr td{padding:.5em .625em .625em;font-size:inherit;color:rgba(0,0,0,.8);text-align:left}
table tr th,table tr td{padding:.5625em .625em;font-size:inherit;color:rgba(0,0,0,.8)}
table tr.even,table tr.alt{background:#f8f8f7}
table thead tr th,table tfoot tr th,table tbody tr td,table tr td,table tfoot tr td{line-height:1.6}
h1,h2,h3,#toctitle,.sidebarblock>.content>.title,h4,h5,h6{line-height:1.2;word-spacing:-.05em}
h1 strong,h2 strong,h3 strong,#toctitle strong,.sidebarblock>.content>.title strong,h4 strong,h5 strong,h6 strong{font-weight:400}
.center{margin-left:auto;margin-right:auto}
.stretch{width:100%}
.clearfix::before,.clearfix::after,.float-group::before,.float-group::after{content:" ";display:table}
.clearfix::after,.float-group::after{clear:both}
:not(pre).nobreak{word-wrap:normal}
:not(pre).nowrap{white-space:nowrap}
:not(pre).pre-wrap{white-space:pre-wrap}
:not(pre):not([class^=L])>code{font-size:.9375em;font-style:normal!important;letter-spacing:0;padding:.1em .5ex;word-spacing:-.15em;background:#f7f7f8;border-radius:4px;line-height:1.45;text-rendering:optimizeSpeed}
pre{color:rgba(0,0,0,.9);font-family:"Droid Sans Mono","DejaVu Sans Mono",monospace;line-height:1.45;text-rendering:optimizeSpeed}
pre code,pre pre{color:inherit;font-size:inherit;line-height:inherit}
pre>code{display:block}
pre.nowrap,pre.nowrap pre{white-space:pre;word-wrap:normal}
em em{font-style:normal}
strong strong{font-weight:400}
.keyseq{color:rgba(51,51,51,.8)}
kbd{font-family:"Droid Sans Mono","DejaVu Sans Mono",monospace;display:inline-block;color:rgba(0,0,0,.8);font-size:.65em;line-height:1.45;background:#f7f7f7;border:1px solid #ccc;border-radius:3px;box-shadow:0 1px 0 rgba(0,0,0,.2),inset 0 0 0 .1em #fff;margin:0 .15em;padding:.2em .5em;vertical-align:middle;position:relative;top:-.1em;white-space:nowrap}
.keyseq kbd:first-child{margin-left:0}
.keyseq kbd:last-child{margin-right:0}
.menuseq,.menuref{color:#000}
.menuseq b:not(.caret),.menuref{font-weight:inherit}
.menuseq{word-spacing:-.02em}
.menuseq b.caret{font-size:1.25em;line-height:.8}
.menuseq i.caret{font-weight:bold;text-align:center;width:.45em}
b.button::before,b.button::after{position:relative;top:-1px;font-weight:400}
b.button::before{content:"[";padding:0 3px 0 2px}
b.button::after{content:"]";padding:0 2px 0 3px}
p a>code:hover{color:rgba(0,0,0,.9)}
#header,#content,#footnotes,#footer{width:100%;margin:0 auto;max-width:62.5em;*zoom:1;position:relative;padding-left:.9375em;padding-right:.9375em}
#header::before,#header::after,#content::before,#content::after,#footnotes::before,#footnotes::after,#footer::before,#footer::after{content:" ";display:table}
#header::after,#content::after,#footnotes::after,#footer::after{clear:both}
#content{margin-top:1.25em}
#content::before{content:none}
#header>h1:first-child{color:rgba(0,0,0,.85);margin-top:2.25rem;margin-bottom:0}
#header>h1:first-child+#toc{margin-top:8px;border-top:1px solid #dddddf}
#header>h1:only-child,body.toc2 #header>h1:nth-last-child(2){border-bottom:1px solid #dddddf;padding-bottom:8px}
#header .details{border-bottom:1px solid #dddddf;line-height:1.45;padding-top:.25em;padding-bottom:.25em;padding-left:.25em;color:rgba(0,0,0,.6);display:flex;flex-flow:row wrap}
#header .details span:first-child{margin-left:-.125em}
#header .details span.email a{color:rgba(0,0,0,.85)}
#header .details br{display:none}
#header .details br+span::before{content:"\00a0\2013\00a0"}
#header .details br+span.author::before{content:"\00a0\22c5\00a0";color:rgba(0,0,0,.85)}
#header .details br+span#revremark::before{content:"\00a0|\00a0"}
#header #revnumber{text-transform:capitalize}
#header #revnumber::after{content:"\00a0"}
#content>h1:first-child:not([class]){color:rgba(0,0,0,.85);border-bottom:1px solid #dddddf;padding-bottom:8px;margin-top:0;padding-top:1rem;margin-bottom:1.25rem}
#toc{border-bottom:1px solid #e7e7e9;padding-bottom:.5em}
#toc>ul{margin-left:.125em}
#toc ul.sectlevel0>li>a{font-style:italic}
#toc ul.sectlevel0 ul.sectlevel1{margin:.5em 0}
#toc ul{font-family:"Open Sans","DejaVu Sans",sans-serif;list-style-type:none}
#toc li{line-height:1.3334;margin-top:.3334em}
#toc a{text-decoration:none}
#toc a:active{text-decoration:underline}
#toctitle{color:#7a2518;font-size:1.2em}
@media screen and (min-width:768px){#toctitle{font-size:1.375em}
body.toc2{padding-left:15em;padding-right:0}
#toc.toc2{margin-top:0!important;background:#f8f8f7;position:fixed;width:15em;left:0;top:0;border-right:1px solid #e7e7e9;border-top-width:0!important;border-bottom-width:0!important;z-index:1000;padding:1.25em 1em;height:100%;overflow:auto}
#toc.toc2 #toctitle{margin-top:0;margin-bottom:.8rem;font-size:1.2em}
#toc.toc2>ul{font-size:.9em;margin-bottom:0}
#toc.toc2 ul ul{margin-left:0;padding-left:1em}
#toc.toc2 ul.sectlevel0 ul.sectlevel1{padding-left:0;margin-top:.5em;margin-bottom:.5em}
body.toc2.toc-right{padding-left:0;padding-right:15em}
body.toc2.toc-right #toc.toc2{border-right-width:0;border-left:1px solid #e7e7e9;left:auto;right:0}}
@media screen and (min-width:1280px){body.toc2{padding-left:20em;padding-right:0}
#toc.toc2{width:20em}
#toc.toc2 #toctitle{font-size:1.375em}
#toc.toc2>ul{font-size:.95em}
#toc.toc2 ul ul{padding-left:1.25em}
body.toc2.toc-right{padding-left:0;padding-right:20em}}
#content #toc{border:1px solid #e0e0dc;margin-bottom:1.25em;padding:1.25em;background:#f8f8f7;border-radius:4px}
#content #toc>:first-child{margin-top:0}
#content #toc>:last-child{margin-bottom:0}
#footer{max-width:none;background:rgba(0,0,0,.8);padding:1.25em}
#footer-text{color:hsla(0,0%,100%,.8);line-height:1.44}
#content{margin-bottom:.625em}
.sect1{padding-bottom:.625em}
@media screen and (min-width:768px){#content{margin-bottom:1.25em}
.sect1{padding-bottom:1.25em}}
.sect1:last-child{padding-bottom:0}
.sect1+.sect1{border-top:1px solid #e7e7e9}
#content h1>a.anchor,h2>a.anchor,h3>a.anchor,#toctitle>a.anchor,.sidebarblock>.content>.title>a.anchor,h4>a.anchor,h5>a.anchor,h6>a.anchor{position:absolute;z-index:1001;width:1.5ex;margin-left:-1.5ex;display:block;text-decoration:none!important;visibility:hidden;text-align:center;font-weight:400}
#content h1>a.anchor::before,h2>a.anchor::before,h3>a.anchor::before,#toctitle>a.anchor::before,.sidebarblock>.content>.title>a.anchor::before,h4>a.anchor::before,h5>a.anchor::before,h6>a.anchor::before{content:"\00A7";font-size:.85em;display:block;padding-top:.1em}
#content h1:hover>a.anchor,#content h1>a.anchor:hover,h2:hover>a.anchor,h2>a.anchor:hover,h3:hover>a.anchor,#toctitle:hover>a.anchor,.sidebarblock>.content>.title:hover>a.anchor,h3>a.anchor:hover,#toctitle>a.anchor:hover,.sidebarblock>.content>.title>a.anchor:hover,h4:hover>a.anchor,h4>a.anchor:hover,h5:hover>a.anchor,h5>a.anchor:hover,h6:hover>a.anchor,h6>a.anchor:hover{visibility:visible}
#content h1>a.link,h2>a.link,h3>a.link,#toctitle>a.link,.sidebarblock>.content>.title>a.link,h4>a.link,h5>a.link,h6>a.link{color:#ba3925;text-decoration:none}
#content h1>a.link:hover,h2>a.link:hover,h3>a.link:hover,#toctitle>a.link:hover,.sidebarblock>.content>.title>a.link:hover,h4>a.link:hover,h5>a.link:hover,h6>a.link:hover{color:#a53221}
details,.audioblock,.imageblock,.literalblock,.listingblock,.stemblock,.videoblock{margin-bottom:1.25em}
details{margin-left:1.25rem}
details>summary{cursor:pointer;display:block;position:relative;line-height:1.6;margin-bottom:.625rem;outline:none;-webkit-tap-highlight-color:transparent}
details>summary::-webkit-details-marker{display:none}
details>summary::before{content:"";border:solid transparent;border-left:solid;border-width:.3em 0 .3em .5em;position:absolute;top:.5em;left:-1.25rem;transform:translateX(15%)}
details[open]>summary::before{border:solid transparent;border-top:solid;border-width:.5em .3em 0;transform:translateY(15%)}
details>summary::after{content:"";width:1.25rem;height:1em;position:absolute;top:.3em;left:-1.25rem}
.admonitionblock td.content>.title,.audioblock>.title,.exampleblock>.title,.imageblock>.title,.listingblock>.title,.literalblock>.title,.stemblock>.title,.openblock>.title,.paragraph>.title,.quoteblock>.title,table.tableblock>.title,.verseblock>.title,.videoblock>.title,.dlist>.title,.olist>.title,.ulist>.title,.qlist>.title,.hdlist>.title{text-rendering:optimizeLegibility;text-align:left;font-family:"Noto Serif","DejaVu Serif",serif;font-size:1rem;font-style:italic}
table.tableblock.fit-content>caption.title{white-space:nowrap;width:0}
.paragraph.lead>p,#preamble>.sectionbody>[class=paragraph]:first-of-type p{font-size:1.21875em;line-height:1.6;color:rgba(0,0,0,.85)}
.admonitionblock>table{border-collapse:separate;border:0;background:none;width:100%}
.admonitionblock>table td.icon{text-align:center;width:80px}
.admonitionblock>table td.icon img{max-width:none}
.admonitionblock>table td.icon .title{font-weight:bold;font-family:"Open Sans","DejaVu Sans",sans-serif;text-transform:uppercase}
.admonitionblock>table td.content{padding-left:1.125em;padding-right:1.25em;border-left:1px solid #dddddf;color:rgba(0,0,0,.6);word-wrap:anywhere}
.admonitionblock>table td.content>:last-child>:last-child{margin-bottom:0}
.exampleblock>.content{border:1px solid #e6e6e6;margin-bottom:1.25em;padding:1.25em;background:#fff;border-radius:4px}
.sidebarblock{border:1px solid #dbdbd6;margin-bottom:1.25em;padding:1.25em;background:#f3f3f2;border-radius:4px}
.sidebarblock>.content>.title{color:#7a2518;margin-top:0;text-align:center}
.exampleblock>.content>:first-child,.sidebarblock>.content>:first-child{margin-top:0}
.exampleblock>.content>:last-child,.exampleblock>.content>:last-child>:last-child,.exampleblock>.content .olist>ol>li:last-child>:last-child,.exampleblock>.content .ulist>ul>li:last-child>:last-child,.exampleblock>.content .qlist>ol>li:last-child>:last-child,.sidebarblock>.content>:last-child,.sidebarblock>.content>:last-child>:last-child,.sidebarblock>.content .olist>ol>li:last-child>:last-child,.sidebarblock>.content .ulist>ul>li:last-child>:last-child,.sidebarblock>.content .qlist>ol>li:last-child>:last-child{margin-bottom:0}
.literalblock pre,.listingblock>.content>pre{border-radius:4px;overflow-x:auto;padding:1em;font-size:.8125em}
@media screen and (min-width:768px){.literalblock pre,.listingblock>.content>pre{font-size:.90625em}}
@media screen and (min-width:1280px){.literalblock pre,.listingblock>.content>pre{font-size:1em}}
.literalblock pre,.listingblock>.content>pre:not(.highlight),.listingblock>.content>pre[class=highlight],.listingblock>.content>pre[class^="highlight "]{background:#f7f7f8}
.literalblock.output pre{color:#f7f7f8;background:rgba(0,0,0,.9)}
.listingblock>.content{position:relative}
.listingblock code[data-lang]::before{display:none;content:attr(data-lang);position:absolute;font-size:.75em;top:.425rem;right:.5rem;line-height:1;text-transform:uppercase;color:inherit;opacity:.5}
.listingblock:hover code[data-lang]::before{display:block}
.listingblock.terminal pre .command::before{content:attr(data-prompt);padding-right:.5em;color:inherit;opacity:.5}
.listingblock.terminal pre .command:not([data-prompt])::before{content:"$"}
.listingblock pre.highlightjs{padding:0}
.listingblock pre.highlightjs>code{padding:1em;border-radius:4px}
.listingblock pre.prettyprint{border-width:0}
.prettyprint{background:#f7f7f8}
pre.prettyprint .linenums{line-height:1.45;margin-left:2em}
pre.prettyprint li{background:none;list-style-type:inherit;padding-left:0}
pre.prettyprint li code[data-lang]::before{opacity:1}
pre.prettyprint li:not(:first-child) code[data-lang]::before{display:none}
table.linenotable{border-collapse:separate;border:0;margin-bottom:0;background:none}
table.linenotable td[class]{color:inherit;vertical-align:top;padding:0;line-height:inherit;white-space:normal}
table.linenotable td.code{padding-left:.75em}
table.linenotable td.linenos,pre.pygments .linenos{border-right:1px solid;opacity:.35;padding-right:.5em;-webkit-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none}
pre.pygments span.linenos{display:inline-block;margin-right:.75em}
.quoteblock{margin:0 1em 1.25em 1.5em;display:table}
.quoteblock:not(.excerpt)>.title{margin-left:-1.5em;margin-bottom:.75em}
.quoteblock blockquote,.quoteblock p{color:rgba(0,0,0,.85);font-size:1.15rem;line-height:1.75;word-spacing:.1em;letter-spacing:0;font-style:italic;text-align:justify}
.quoteblock blockquote{margin:0;padding:0;border:0}
.quoteblock blockquote::before{content:"\201c";float:left;font-size:2.75em;font-weight:bold;line-height:.6em;margin-left:-.6em;color:#7a2518;text-shadow:0 1px 2px rgba(0,0,0,.1)}
.quoteblock blockquote>.paragraph:last-child p{margin-bottom:0}
.quoteblock .attribution{margin-top:.75em;margin-right:.5ex;text-align:right}
.verseblock{margin:0 1em 1.25em}
.verseblock pre{font-family:"Open Sans","DejaVu Sans",sans-serif;font-size:1.15rem;color:rgba(0,0,0,.85);font-weight:300;text-rendering:optimizeLegibility}
.verseblock pre strong{font-weight:400}
.verseblock .attribution{margin-top:1.25rem;margin-left:.5ex}
.quoteblock .attribution,.verseblock .attribution{font-size:.9375em;line-height:1.45;font-style:italic}
.quoteblock .attribution br,.verseblock .attribution br{display:none}
.quoteblock .attribution cite,.verseblock .attribution cite{display:block;letter-spacing:-.025em;color:rgba(0,0,0,.6)}
.quoteblock.abstract blockquote::before,.quoteblock.excerpt blockquote::before,.quoteblock .quoteblock blockquote::before{display:none}
.quoteblock.abstract blockquote,.quoteblock.abstract p,.quoteblock.excerpt blockquote,.quoteblock.excerpt p,.quoteblock .quoteblock blockquote,.quoteblock .quoteblock p{line-height:1.6;word-spacing:0}
.quoteblock.abstract{margin:0 1em 1.25em;display:block}
.quoteblock.abstract>.title{margin:0 0 .375em;font-size:1.15em;text-align:center}
.quoteblock.excerpt>blockquote,.quoteblock .quoteblock{padding:0 0 .25em 1em;border-left:.25em solid #dddddf}
.quoteblock.excerpt,.quoteblock .quoteblock{margin-left:0}
.quoteblock.excerpt blockquote,.quoteblock.excerpt p,.quoteblock .quoteblock blockquote,.quoteblock .quoteblock p{color:inherit;font-size:1.0625rem}
.quoteblock.excerpt .attribution,.quoteblock .quoteblock .attribution{color:inherit;font-size:.85rem;text-align:left;margin-right:0}
p.tableblock:last-child{margin-bottom:0}
td.tableblock>.content{margin-bottom:1.25em;word-wrap:anywhere}
td.tableblock>.content>:last-child{margin-bottom:-1.25em}
table.tableblock,th.tableblock,td.tableblock{border:0 solid #dedede}
table.grid-all>*>tr>*{border-width:1px}
table.grid-cols>*>tr>*{border-width:0 1px}
table.grid-rows>*>tr>*{border-width:1px 0}
table.frame-all{border-width:1px}
table.frame-ends{border-width:1px 0}
table.frame-sides{border-width:0 1px}
table.frame-none>colgroup+*>:first-child>*,table.frame-sides>colgroup+*>:first-child>*{border-top-width:0}
table.frame-none>:last-child>:last-child>*,table.frame-sides>:last-child>:last-child>*{border-bottom-width:0}
table.frame-none>*>tr>:first-child,table.frame-ends>*>tr>:first-child{border-left-width:0}
table.frame-none>*>tr>:last-child,table.frame-ends>*>tr>:last-child{border-right-width:0}
table.stripes-all>*>tr,table.stripes-odd>*>tr:nth-of-type(odd),table.stripes-even>*>tr:nth-of-type(even),table.stripes-hover>*>tr:hover{background:#f8f8f7}
th.halign-left,td.halign-left{text-align:left}
th.halign-right,td.halign-right{text-align:right}
th.halign-center,td.halign-center{text-align:center}
th.valign-top,td.valign-top{vertical-align:top}
th.valign-bottom,td.valign-bottom{vertical-align:bottom}
th.valign-middle,td.valign-middle{vertical-align:middle}
table thead th,table tfoot th{font-weight:bold}
tbody tr th{background:#f7f8f7}
tbody tr th,tbody tr th p,tfoot tr th,tfoot tr th p{color:rgba(0,0,0,.8);font-weight:bold}
p.tableblock>code:only-child{background:none;padding:0}
p.tableblock{font-size:1em}
ol{margin-left:1.75em}
ul li ol{margin-left:1.5em}
dl dd{margin-left:1.125em}
dl dd:last-child,dl dd:last-child>:last-child{margin-bottom:0}
li p,ul dd,ol dd,.olist .olist,.ulist .ulist,.ulist .olist,.olist .ulist{margin-bottom:.625em}
ul.checklist,ul.none,ol.none,ul.no-bullet,ol.no-bullet,ol.unnumbered,ul.unstyled,ol.unstyled{list-style-type:none}
ul.no-bullet,ol.no-bullet,ol.unnumbered{margin-left:.625em}
ul.unstyled,ol.unstyled{margin-left:0}
li>p:empty:only-child::before{content:"";display:inline-block}
ul.checklist>li>p:first-child{margin-left:-1em}
ul.checklist>li>p:first-child>.fa-square-o:first-child,ul.checklist>li>p:first-child>.fa-check-square-o:first-child{width:1.25em;font-size:.8em;position:relative;bottom:.125em}
ul.checklist>li>p:first-child>input[type=checkbox]:first-child{margin-right:.25em}
ul.inline{display:flex;flex-flow:row wrap;list-style:none;margin:0 0 .625em -1.25em}
ul.inline>li{margin-left:1.25em}
.unstyled dl dt{font-weight:400;font-style:normal}
ol.arabic{list-style-type:decimal}
ol.decimal{list-style-type:decimal-leading-zero}
ol.loweralpha{list-style-type:lower-alpha}
ol.upperalpha{list-style-type:upper-alpha}
ol.lowerroman{list-style-type:lower-roman}
ol.upperroman{list-style-type:upper-roman}
ol.lowergreek{list-style-type:lower-greek}
.hdlist>table,.colist>table{border:0;background:none}
.hdlist>table>tbody>tr,.colist>table>tbody>tr{background:none}
td.hdlist1,td.hdlist2{vertical-align:top;padding:0 .625em}
td.hdlist1{font-weight:bold;padding-bottom:1.25em}
td.hdlist2{word-wrap:anywhere}
.literalblock+.colist,.listingblock+.colist{margin-top:-.5em}
.colist td:not([class]):first-child{padding:.4em .75em 0;line-height:1;vertical-align:top}
.colist td:not([class]):first-child img{max-width:none}
.colist td:not([class]):last-child{padding:.25em 0}
.thumb,.th{line-height:0;display:inline-block;border:4px solid #fff;box-shadow:0 0 0 1px #ddd}
.imageblock.left{margin:.25em .625em 1.25em 0}
.imageblock.right{margin:.25em 0 1.25em .625em}
.imageblock>.title{margin-bottom:0}
.imageblock.thumb,.imageblock.th{border-width:6px}
.imageblock.thumb>.title,.imageblock.th>.title{padding:0 .125em}
.image.left,.image.right{margin-top:.25em;margin-bottom:.25em;display:inline-block;line-height:0}
.image.left{margin-right:.625em}
.image.right{margin-left:.625em}
a.image{text-decoration:none;display:inline-block}
a.image object{pointer-events:none}
sup.footnote,sup.footnoteref{font-size:.875em;position:static;vertical-align:super}
sup.footnote a,sup.footnoteref a{text-decoration:none}
sup.footnote a:active,sup.footnoteref a:active{text-decoration:underline}
#footnotes{padding-top:.75em;padding-bottom:.75em;margin-bottom:.625em}
#footnotes hr{width:20%;min-width:6.25em;margin:-.25em 0 .75em;border-width:1px 0 0}
#footnotes .footnote{padding:0 .375em 0 .225em;line-height:1.3334;font-size:.875em;margin-left:1.2em;margin-bottom:.2em}
#footnotes .footnote a:first-of-type{font-weight:bold;text-decoration:none;margin-left:-1.05em}
#footnotes .footnote:last-of-type{margin-bottom:0}
#content #footnotes{margin-top:-.625em;margin-bottom:0;padding:.75em 0}
div.unbreakable{page-break-inside:avoid}
.big{font-size:larger}
.small{font-size:smaller}
.underline{text-decoration:underline}
.overline{text-decoration:overline}
.line-through{text-decoration:line-through}
.aqua{color:#00bfbf}
.aqua-background{background:#00fafa}
.black{color:#000}
.black-background{background:#000}
.blue{color:#0000bf}
.blue-background{background:#0000fa}
.fuchsia{color:#bf00bf}
.fuchsia-background{background:#fa00fa}
.gray{color:#606060}
.gray-background{background:#7d7d7d}
.green{color:#006000}
.green-background{background:#007d00}
.lime{color:#00bf00}
.lime-background{background:#00fa00}
.maroon{color:#600000}
.maroon-background{background:#7d0000}
.navy{color:#000060}
.navy-background{background:#00007d}
.olive{color:#606000}
.olive-background{background:#7d7d00}
.purple{color:#600060}
.purple-background{background:#7d007d}
.red{color:#bf0000}
.red-background{background:#fa0000}
.silver{color:#909090}
.silver-background{background:#bcbcbc}
.teal{color:#006060}
.teal-background{background:#007d7d}
.white{color:#bfbfbf}
.white-background{background:#fafafa}
.yellow{color:#bfbf00}
.yellow-background{background:#fafa00}
span.icon>.fa{cursor:default}
a span.icon>.fa{cursor:inherit}
.admonitionblock td.icon [class^="fa icon-"]{font-size:2.5em;text-shadow:1px 1px 2px rgba(0,0,0,.5);cursor:default}
.admonitionblock td.icon .icon-note::before{content:"\f05a";color:#19407c}
.admonitionblock td.icon .icon-tip::before{content:"\f0eb";text-shadow:1px 1px 2px rgba(155,155,0,.8);color:#111}
.admonitionblock td.icon .icon-warning::before{content:"\f071";color:#bf6900}
.admonitionblock td.icon .icon-caution::before{content:"\f06d";color:#bf3400}
.admonitionblock td.icon .icon-important::before{content:"\f06a";color:#bf0000}
.conum[data-value]{display:inline-block;color:#fff!important;background:rgba(0,0,0,.8);border-radius:50%;text-align:center;font-size:.75em;width:1.67em;height:1.67em;line-height:1.67em;font-family:"Open Sans","DejaVu Sans",sans-serif;font-style:normal;font-weight:bold}
.conum[data-value] *{color:#fff!important}
.conum[data-value]+b{display:none}
.conum[data-value]::after{content:attr(data-value)}
pre .conum[data-value]{position:relative;top:-.125em}
b.conum *{color:inherit!important}
.conum:not([data-value]):empty{display:none}
dt,th.tableblock,td.content,div.footnote{text-rendering:optimizeLegibility}
h1,h2,p,td.content,span.alt,summary{letter-spacing:-.01em}
p strong,td.content strong,div.footnote strong{letter-spacing:-.005em}
p,blockquote,dt,td.content,td.hdlist1,span.alt,summary{font-size:1.0625rem}
p{margin-bottom:1.25rem}
.sidebarblock p,.sidebarblock dt,.sidebarblock td.content,p.tableblock{font-size:1em}
.exampleblock>.content{background:#fffef7;border-color:#e0e0dc;box-shadow:0 1px 4px #e0e0dc}
.print-only{display:none!important}
@page{margin:1.25cm .75cm}
@media print{*{box-shadow:none!important;text-shadow:none!important}
html{font-size:80%}
a{color:inherit!important;text-decoration:underline!important}
a.bare,a[href^="#"],a[href^="mailto:"]{text-decoration:none!important}
a[href^="http:"]:not(.bare)::after,a[href^="https:"]:not(.bare)::after{content:"(" attr(href) ")";display:inline-block;font-size:.875em;padding-left:.25em}
abbr[title]{border-bottom:1px dotted}
abbr[title]::after{content:" (" attr(title) ")"}
pre,blockquote,tr,img,object,svg{page-break-inside:avoid}
thead{display:table-header-group}
svg{max-width:100%}
p,blockquote,dt,td.content{font-size:1em;orphans:3;widows:3}
h2,h3,#toctitle,.sidebarblock>.content>.title{page-break-after:avoid}
#header,#content,#footnotes,#footer{max-width:none}
#toc,.sidebarblock,.exampleblock>.content{background:none!important}
#toc{border-bottom:1px solid #dddddf!important;padding-bottom:0!important}
body.book #header{text-align:center}
body.book #header>h1:first-child{border:0!important;margin:2.5em 0 1em}
body.book #header .details{border:0!important;display:block;padding:0!important}
body.book #header .details span:first-child{margin-left:0!important}
body.book #header .details br{display:block}
body.book #header .details br+span::before{content:none!important}
body.book #toc{border:0!important;text-align:left!important;padding:0!important;margin:0!important}
body.book #toc,body.book #preamble,body.book h1.sect0,body.book .sect1>h2{page-break-before:always}
.listingblock code[data-lang]::before{display:block}
#footer{padding:0 .9375em}
.hide-on-print{display:none!important}
.print-only{display:block!important}
.hide-for-print{display:none!important}
.show-for-print{display:inherit!important}}
@media amzn-kf8,print{#header>h1:first-child{margin-top:1.25rem}
.sect1{padding:0!important}
.sect1+.sect1{border:0}
#footer{background:none}
#footer-text{color:rgba(0,0,0,.6);font-size:.9em}}
@media amzn-kf8{#header,#content,#footnotes,#footer{padding:0}}
</style>
<style>
/*! Stylesheet for CodeRay to loosely match GitHub themes | MIT License */
pre.CodeRay{background:#f7f7f8}
.CodeRay .line-numbers{border-right:1px solid;opacity:.35;padding:0 .5em 0 0;-webkit-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none}
.CodeRay span.line-numbers{display:inline-block;margin-right:.75em}
.CodeRay .line-numbers strong{color:#000}
table.CodeRay{border-collapse:separate;border:0;margin-bottom:0;background:none}
table.CodeRay td{vertical-align:top;line-height:inherit}
table.CodeRay td.line-numbers{text-align:right}
table.CodeRay td.code{padding:0 0 0 .75em}
.CodeRay .debug{color:#fff!important;background:navy!important}
.CodeRay .annotation{color:#007}
.CodeRay .attribute-name{color:navy}
.CodeRay .attribute-value{color:#700}
.CodeRay .binary{color:#509}
.CodeRay .comment{color:#998;font-style:italic}
.CodeRay .char{color:#04d}
.CodeRay .char .content{color:#04d}
.CodeRay .char .delimiter{color:#039}
.CodeRay .class{color:#458;font-weight:bold}
.CodeRay .complex{color:#a08}
.CodeRay .constant,.CodeRay .predefined-constant{color:teal}
.CodeRay .color{color:#099}
.CodeRay .class-variable{color:#369}
.CodeRay .decorator{color:#b0b}
.CodeRay .definition{color:#099}
.CodeRay .delimiter{color:#000}
.CodeRay .doc{color:#970}
.CodeRay .doctype{color:#34b}
.CodeRay .doc-string{color:#d42}
.CodeRay .escape{color:#666}
.CodeRay .entity{color:#800}
.CodeRay .error{color:#808}
.CodeRay .exception{color:inherit}
.CodeRay .filename{color:#099}
.CodeRay .function{color:#900;font-weight:bold}
.CodeRay .global-variable{color:teal}
.CodeRay .hex{color:#058}
.CodeRay .integer,.CodeRay .float{color:#099}
.CodeRay .include{color:#555}
.CodeRay .inline{color:#000}
.CodeRay .inline .inline{background:#ccc}
.CodeRay .inline .inline .inline{background:#bbb}
.CodeRay .inline .inline-delimiter{color:#d14}
.CodeRay .inline-delimiter{color:#d14}
.CodeRay .important{color:#555;font-weight:bold}
.CodeRay .interpreted{color:#b2b}
.CodeRay .instance-variable{color:teal}
.CodeRay .label{color:#970}
.CodeRay .local-variable{color:#963}
.CodeRay .octal{color:#40e}
.CodeRay .predefined{color:#369}
.CodeRay .preprocessor{color:#579}
.CodeRay .pseudo-class{color:#555}
.CodeRay .directive{font-weight:bold}
.CodeRay .type{font-weight:bold}
.CodeRay .predefined-type{color:inherit}
.CodeRay .reserved,.CodeRay .keyword{color:#000;font-weight:bold}
.CodeRay .key{color:#808}
.CodeRay .key .delimiter{color:#606}
.CodeRay .key .char{color:#80f}
.CodeRay .value{color:#088}
.CodeRay .regexp .delimiter{color:#808}
.CodeRay .regexp .content{color:#808}
.CodeRay .regexp .modifier{color:#808}
.CodeRay .regexp .char{color:#d14}
.CodeRay .regexp .function{color:#404;font-weight:bold}
.CodeRay .string{color:#d20}
.CodeRay .string .string .string{background:#ffd0d0}
.CodeRay .string .content{color:#d14}
.CodeRay .string .char{color:#d14}
.CodeRay .string .delimiter{color:#d14}
.CodeRay .shell{color:#d14}
.CodeRay .shell .delimiter{color:#d14}
.CodeRay .symbol{color:#990073}
.CodeRay .symbol .content{color:#a60}
.CodeRay .symbol .delimiter{color:#630}
.CodeRay .tag{color:teal}
.CodeRay .tag-special{color:#d70}
.CodeRay .variable{color:#036}
.CodeRay .insert{background:#afa}
.CodeRay .delete{background:#faa}
.CodeRay .change{color:#aaf;background:#007}
.CodeRay .head{color:#f8f;background:#505}
.CodeRay .insert .insert{color:#080}
.CodeRay .delete .delete{color:#800}
.CodeRay .change .change{color:#66f}
.CodeRay .head .head{color:#f4f}
</style>
</head>
<body class="article">
<div id="header">
<h1>23-08 Deep Learning with Python - 2nd Edition</h1>
<div class="details">
<span id="author" class="author">François Chollet</span><br>
</div>
<div id="toc" class="toc">
<div id="toctitle">Table of Contents</div>
<ul class="sectlevel1">
<li><a href="#_1_what_is_deep_learning">1 What is deep learning?</a>
<ul class="sectlevel2">
<li><a href="#_1_1_artificial_intelligence_machine_learning_and_deep_learning">1.1 Artificial intelligence, machine learning, and deep learning</a></li>
<li><a href="#_1_2_before_deep_learning_a_brief_history_of_machine_learning">1.2 Before deep learning - A brief history of machine learning</a></li>
<li><a href="#_1_3_why_deep_learning_why_now">1.3 Why deep learning - Why now</a></li>
</ul>
</li>
<li><a href="#_2_the_mathematical_building_blocks_of_neural_networks">2 The mathematical building blocks of neural networks</a>
<ul class="sectlevel2">
<li><a href="#_2_1_a_first_look_at_a_neural_network">2.1 A first look at a neural network</a></li>
<li><a href="#_2_2_data_representations_for_neural_networks">2.2 Data representations for neural networks</a></li>
<li><a href="#_2_3_the_gears_of_neural_networks_tensor_operations">2.3 The gears of neural networks - Tensor operations</a></li>
<li><a href="#_2_4_the_engine_of_neural_networks_gradient_based_optimization">2.4 The engine of neural networks - Gradient-based optimization</a></li>
<li><a href="#_2_5_looking_back_at_our_first_example">2.5 Looking back at our first example</a></li>
<li><a href="#_summary">Summary</a></li>
</ul>
</li>
</ul>
</div>
</div>
<div id="content">
<div class="sect1">
<h2 id="_1_what_is_deep_learning">1 What is deep learning?</h2>
<div class="sectionbody">
<div class="sect2">
<h3 id="_1_1_artificial_intelligence_machine_learning_and_deep_learning">1.1 Artificial intelligence, machine learning, and deep learning</h3>
<div class="paragraph">
<p>The layer&#8217;s function in processing input data is determined by its <em>weights</em>, which are numerical values. Technically, the layer&#8217;s operation is <em>parameterized</em> by these weights, which can also be referred to as the layer&#8217;s <em>parameters</em>.</p>
</div>
<div class="paragraph">
<p><em>Learning</em> in this context involves identifying the proper values for the weights across all layers in a network so that the network accurately associates input examples with their corresponding targets.</p>
</div>
<div class="paragraph">
<p>To manage the output of a neural network, it&#8217;s essential to monitor it, which is done through a <em>loss function</em>. The loss function evaluates the network&#8217;s predictions against the desired targets by calculating a distance score, indicating the network&#8217;s performance on a given example. This function is also known as the <em>objective function</em> or <em>cost function</em>.</p>
</div>
</div>
<div class="sect2">
<h3 id="_1_2_before_deep_learning_a_brief_history_of_machine_learning">1.2 Before deep learning - A brief history of machine learning</h3>
<div class="paragraph">
<p><em>Probabilistic modeling</em> uses statistical principles for data analysis and is foundational in machine learning. The Naive Bayes algorithm is a well-known example that applies Bayes' theorem with the assumption that all input features are independent. This technique has been in use since before the advent of computers, with its principles dating back to the 18th century. <em>Logistic regression</em> is another related model which, despite its name, is used for classification tasks. It is also an old but still relevant technique, commonly used as an initial approach by data scientists for its simplicity and versatility.</p>
</div>
<div class="paragraph">
<p>Deep learning has gained popularity not only because of its superior performance on many tasks but also because it simplifies problem-solving by eliminating the need for <em>feature engineering</em>. In traditional machine learning methods, called shallow learning, humans had to manually create and fine-tune features from the data for the algorithms to work effectively. Deep learning, however, automates this process by learning all necessary features in a single pass through a multi-layered network structure.</p>
</div>
<div class="paragraph">
<p>Shallow learning methods like SVMs or decision trees only transform data into one or two layers of representation, which often isn&#8217;t sufficient for complex problems. Attempting to apply shallow methods in succession to mimic deep learning is inefficient because each layer&#8217;s optimal representation isn&#8217;t the same across different model complexities. Deep learning&#8217;s transformative approach is its ability to <em>learn multiple layers of representation jointly</em>. This means that all layers adjust together in response to a single feedback signal, allowing the model to develop increasingly complex and abstract representations through a series of simple transformations across layers.</p>
</div>
<div class="paragraph">
<p>The two key aspects of how deep learning learns from data are the <em>incremental development of more complex representations through multiple layers</em> and the <em>joint learning of these representations</em>, which enables each layer to be refined in coordination with the others. These properties have made deep learning much more effective than previous machine learning methods.</p>
</div>
<div class="paragraph">
<p>From 2016 to 2020, the machine learning and data science field has been primarily focused on two methodologies: deep learning for perceptual tasks like image classification, and gradient boosted trees for structured data problems. Practitioners use Python libraries such as Scikit-learn, XGBoost, and LightGBM for gradient boosted trees and Keras, often with TensorFlow, for deep learning. Proficiency in these techniques and tools is considered crucial for success in applied machine learning, and they are frequently used in Kaggle competitions.</p>
</div>
</div>
<div class="sect2">
<h3 id="_1_3_why_deep_learning_why_now">1.3 Why deep learning - Why now</h3>
<div class="paragraph">
<p>Deep learning is considered a significant advancement in AI with several properties that make it a robust and long-lasting approach, likely to influence future technologies. These properties include:</p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p><em>Simplicity:</em> Deep learning simplifies model building by eliminating the need for feature engineering, allowing for end-to-end training with a limited set of operations.</p>
</li>
<li>
<p><em>Scalability:</em> It benefits from GPU or TPU parallelization and can handle vast datasets thanks to batch-based training, making it compatible with the ongoing improvements in computational power.</p>
</li>
<li>
<p><em>Versatility and Reusability:</em> Deep learning models can be continuously updated with new data and repurposed for different tasks, making them adaptable and efficient for various applications, even with smaller datasets.</p>
</li>
</ol>
</div>
<div class="paragraph">
<p>While deep learning has been prominent for only a few years, its potential is still unfolding with new use cases and improvements. The field saw rapid progress initially, which is now stabilizing into more incremental advancements. Innovations like Transformer-based models in natural language processing have marked significant milestones. As of 2021, deep learning may be entering a phase of more steady and less explosive growth, but significant developments are still anticipated in the coming years. The deployment of deep learning across numerous applications is expected to continue, as its full potential has yet to be fully realized.</p>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_2_the_mathematical_building_blocks_of_neural_networks">2 The mathematical building blocks of neural networks</h2>
<div class="sectionbody">
<div class="sect2">
<h3 id="_2_1_a_first_look_at_a_neural_network">2.1 A first look at a neural network</h3>
<div class="paragraph">
<p>An overview of a neural network example using Keras, a Python library, to classify handwritten digits from the MNIST dataset. The dataset includes 60,000 training images and 10,000 test images of grayscale digits, each 28x28 pixels. The classification task involves assigning these images to one of ten classes (0-9).</p>
</div>
<div class="paragraph">
<p>The neural network architecture consists of two densely connected layers. The first layer has 512 units with <code>ReLU</code> activation, and the second is a <code>softmax</code> layer with 10 units, corresponding to the 10 digit classes. The <code>softmax</code> layer outputs a probability distribution across the classes.</p>
</div>
<div class="paragraph">
<p>To prepare the model for training, the following steps are taken:</p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>Compiling the model with an optimizer (<code>RMSprop</code>), a loss function (<code>sparse_categorical_crossentropy</code>), and a metric (<code>accuracy</code>).</p>
</li>
<li>
<p>Preprocessing the image data by reshaping it into a flat array and normalizing pixel values to the range <code>[0, 1]</code>.</p>
</li>
</ol>
</div>
<div class="paragraph">
<p>The model is trained using the <code>fit</code> method on the preprocessed training data for 5 epochs with a batch size of 128. The performance is measured in terms of loss and accuracy on the training data, achieving a high accuracy of 98.9%.</p>
</div>
<div class="paragraph">
<p>After training, the model can predict class probabilities for new images. For example, when the model predicts the class for a test digit, it outputs a probability distribution, with the highest probability indicating the predicted class.</p>
</div>
<div class="paragraph">
<p>Evaluating the model on the test set shows an accuracy of 97.8%, which is slightly lower than the training accuracy due to overfitting—a common issue in machine learning where models perform better on training data than on new, unseen data.</p>
</div>
<div class="paragraph">
<p>The example serves as an introduction to building and training a neural network for digit classification and sets the stage for deeper explanations in subsequent chapters about tensors, tensor operations, and gradient descent. The reader is not expected to understand all details at this point, as the forthcoming chapters will provide a more thorough explanation.</p>
</div>
</div>
<div class="sect2">
<h3 id="_2_2_data_representations_for_neural_networks">2.2 Data representations for neural networks</h3>
<div class="paragraph">
<p>A tensor is a container for numerical data, which generalizes the concept of matrices to higher dimensions, known as axes. The following points summarize the key ideas and examples provided about tensors:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><strong>Scalars (0D tensors)</strong>: A single number, having zero axes (<code>ndim = 0</code>).</p>
</li>
<li>
<p><strong>Vectors (1D tensors)</strong>: An array of numbers, having one axis.</p>
</li>
<li>
<p><strong>Matrices (2D tensors)</strong>: An array of vectors, having two axes (rows and columns).</p>
</li>
<li>
<p><strong>Higher-rank tensors</strong>: Arrays of 2D tensors are 3D tensors, and so on. Deep learning typically involves tensors with 0 to 4 axes, occasionally 5 for video data.</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>Tensors are characterized by three main attributes:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><strong>Number of axes (rank)</strong>: The dimensionality or number of axes in a tensor.</p>
</li>
<li>
<p><strong>Shape</strong>: The dimensions the tensor has along each axis.</p>
</li>
<li>
<p><strong>Data type (dtype)</strong>: The type of data stored in the tensor (e.g., <code>float32</code>, <code>uint8</code>).</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>In the context of machine learning, you often deal with tensors that have specific shapes and meanings, such as:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><strong>Data batches</strong>: The first axis (axis 0) is usually the <em>samples axis</em>, used for mini-batches in training.</p>
</li>
<li>
<p><strong>Real-world data tensors</strong>: These can include vector data (2D tensors), time series or sequence data (3D), images (4D), and videos (5D).</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>Specific examples include:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><strong>Vector data</strong>: Rank-2 tensors with shape <code>(samples, features)</code>.</p>
</li>
<li>
<p><strong>Time series data</strong>: Rank-3 tensors with shape <code>(samples, timesteps, features)</code>.</p>
</li>
<li>
<p><strong>Image data</strong>: Rank-4 tensors with shape <code>(samples, height, width, channels)</code> or <code>(samples, channels, height, width)</code>.</p>
</li>
<li>
<p><strong>Video data</strong>: Rank-5 tensors with shape <code>(samples, frames, height, width, channels)</code>.</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>In practice, slicing tensors allows for selecting specific elements, sequences, or regions from these arrays. For instance, to access a portion of an image or a sequence of data points within a time series.</p>
</div>
<div class="paragraph">
<p>Understanding these tensor operations is crucial for preprocessing and manipulating the data used to train machine learning models, like the example shown where a digit from the MNIST dataset is displayed using Matplotlib, or when taking a specific batch of images from a larger tensor for processing.</p>
</div>
</div>
<div class="sect2">
<h3 id="_2_3_the_gears_of_neural_networks_tensor_operations">2.3 The gears of neural networks - Tensor operations</h3>
<div class="paragraph">
<p><code>relu</code> (rectified linear unit) and addition are element-wise operations that can be applied to each element of tensors independently.</p>
</div>
<div class="paragraph">
<p>Two naive Python implementations of the <code>relu</code> and addition operations are included, which loop over the elements of rank-2 NumPy tensors (2D arrays) and apply the operations in a non-vectorized manner. The <code>relu</code> operation sets each element to the maximum of its current value and zero, while the addition operation sums corresponding elements from two tensors.</p>
</div>
<div class="paragraph">
<p>It is mentioned that, in practice, one would use optimized NumPy functions for these operations, which are significantly faster because they utilize Basic Linear Algebra Subprograms (BLAS) that are low-level, highly optimized, and parallel.</p>
</div>
<div class="paragraph">
<p><em>Broadcasting</em> in the context of tensor addition when the tensors have different shapes
allows for element-wise operations between tensors of different shapes by virtually extending the smaller tensor to match the shape of the larger one without actually copying data.</p>
</div>
<div class="paragraph">
<p>Here&#8217;s a summary of the steps and principles involved in broadcasting:</p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>If one tensor is smaller, it will be virtually "broadcast" to match the shape of the larger tensor for addition.</p>
</li>
<li>
<p>The process involves adding broadcast axes to the smaller tensor so that its number of dimensions (<code>ndim</code>) matches that of the larger tensor.</p>
</li>
<li>
<p>The smaller tensor is then virtually replicated along these new axes to have the same shape as the larger tensor.</p>
</li>
</ol>
</div>
<div class="paragraph">
<p>For example, to add a matrix <code>X</code> with shape <code>(32, 10)</code> and a vector <code>y</code> with shape <code>(10,)</code>, <code>y</code> is first reshaped to <code>(1, 10)</code>. It is then virtually repeated 32 times to form a matrix <code>Y</code> with shape <code>(32, 10)</code>, allowing for the addition with <code>X</code>.</p>
</div>
<div class="paragraph">
<p>Naive Python implementation of matrix-vector addition included, that manually implements broadcasting. Additionally, it mentions that broadcasting can be used with tensors where the smaller tensor&#8217;s shape matches the trailing dimensions of the larger tensor&#8217;s shape. An example of using broadcasting with the <code>np.maximum</code> function is given, where a tensor <code>x</code> of shape <code>(64, 3, 32, 10)</code> is element-wise compared with a tensor <code>y</code> of shape <code>(32, 10)</code> to produce a tensor <code>z</code> of shape <code>(64, 3, 32, 10)</code>.</p>
</div>
<div class="paragraph">
<p>The <em>tensor product</em>, commonly known as the <em>dot product</em>, is a crucial operation in tensor algebra. In NumPy, this operation is performed using the <code>np.dot</code> function. When two vectors are involved, the dot product is a scalar that sums the products of the corresponding elements of equal-length vectors. For a matrix and a vector, the result is a vector whose elements are the dot products of the vector with each row of the matrix. The dot product can also be generalized to two matrices, where it results in a new matrix with elements formed from the dot products of rows of the first matrix with columns of the second matrix. The shapes of the tensors must be compatible, meaning that the length of the row vector in the first matrix must match the length of the column vector in the second matrix. The concept extends to higher-dimensional tensors, where the rule of matching the last dimension of the first tensor with the second-to-last dimension of the second tensor still applies.</p>
</div>
<div class="paragraph">
<p><em>Tensor reshaping</em> is a fundamental operation when working with neural networks. This operation changes the shape of a tensor without altering the total number of elements it contains.</p>
</div>
<div class="paragraph">
<p>Tensor operations can be understood as geometric transformations in space. The addition of two vectors, such as <code>A = [0.5, 1]</code> and <code>B = [1, 0.25]</code>, results in a translation, where vector <code>B</code> moves point <code>A</code> to a new location. Other basic tensor operations that have geometric interpretations include:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><strong>Translation</strong>: Moving an object in space without distortion, represented by vector addition.</p>
</li>
<li>
<p><strong>Rotation</strong>: A counterclockwise rotation around the origin in a 2D space can be achieved by multiplying a vector by a rotation matrix R consisting of sine and cosine values of the rotation angle.</p>
</li>
<li>
<p><strong>Scaling</strong>: Changing the size of an object in space by a certain factor along various axes is achieved by multiplying the object&#8217;s vector representation by a scaling matrix S, which is a diagonal matrix with scaling factors.</p>
</li>
<li>
<p><strong>Linear Transform</strong>: A dot product with any matrix represents a linear transformation, which includes scaling and rotation.</p>
</li>
<li>
<p><strong>Affine Transform</strong>: Combining a linear transform with a translation, similar to the operation done by a Dense layer in neural networks without an activation function.</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>In the context of neural networks, a Dense layer with a <code>relu</code> activation function enables the network to learn non-linear transformations, which is crucial since a sequence of affine transformations without non-linearity would collapse into a single affine transformation. Activation functions like <code>relu</code> introduce non-linearity, allowing deep neural networks to represent complex transformations and hypotheses.</p>
</div>
<div class="paragraph">
<p>Neural networks operate through a series of tensor operations that can be seen as geometric transformations in high-dimensional space, simplifying these transformations into manageable steps. A useful analogy for understanding this concept is to visualize crumpled paper representing mixed classes of data in a 3D space. The goal of a neural network is to 'uncrumple' this ball of paper in order to separate the classes again, making them distinct and easily identifiable. This process is akin to finding simpler representations for complex data structures, known as manifolds, within these high-dimensional spaces. Deep learning is particularly adept at this task because it breaks down the complex disentanglement into a succession of simpler transformations, much like how a person would methodically unfold a crumpled ball of paper. Each layer of the neural network contributes to gradually unraveling the data until the classes are clearly separated.</p>
</div>
</div>
<div class="sect2">
<h3 id="_2_4_the_engine_of_neural_networks_gradient_based_optimization">2.4 The engine of neural networks - Gradient-based optimization</h3>
<div class="paragraph">
<p>Model transforms its input using a layer that applies a dot product with <em>weights</em> (W) and a <em>bias</em> (b), followed by a <code>ReLU</code> activation function. The weights are initially set to small random values and are adjusted during training to minimize the loss, which is the difference between the model&#8217;s predictions and the actual target values.</p>
</div>
<div class="paragraph">
<p>The training process follows these steps:</p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>Select a batch of training data and corresponding targets.</p>
</li>
<li>
<p>Perform a forward pass to generate predictions.</p>
</li>
<li>
<p>Calculate the loss to measure how well the model&#8217;s predictions match the targets.</p>
</li>
<li>
<p>Update the weights to reduce the loss on this batch.</p>
</li>
</ol>
</div>
<div class="paragraph">
<p>Updating the weights is the key challenge in training, and doing this efficiently is crucial. A naive approach of individually tweaking each weight is impractical due to computational expense. Instead, <em>gradient descent</em> is used as an optimization technique. Functions in the model are differentiable, meaning small changes in weights lead to small and predictable changes in the loss. By computing the gradient of the loss with respect to the weights, it&#8217;s possible to adjust all the weights in a direction that reduces the loss.</p>
</div>
<div class="paragraph">
<p>The concept of derivatives extends to functions that take tensors as inputs, creating gradients. A gradient represents how the output of a tensor function changes in response to variations in input.</p>
</div>
<div class="paragraph">
<p>The example provided is in the context of machine learning, where an input vector <code>x</code>, a weight matrix <code>W</code>, and a target <code>y_true</code> are used to compute a loss function, which measures the discrepancy between the predicted output <code>y_pred</code> and the actual target <code>y_true</code>. The goal is to adjust <code>W</code> to minimize the loss.</p>
</div>
<div class="paragraph">
<p>The loss function can be seen as mapping the weights <code>W</code> to loss values, and the gradient of the loss function with respect to <code>W</code> at a point <code>W0</code> indicates how changes in <code>W&#8217;s coefficients affect the loss. This gradient is a tensor with the same shape as `W</code>, and each coefficient shows the direction and magnitude of the impact on the loss value when that specific coefficient in <code>W</code> is tweaked.</p>
</div>
<div class="paragraph">
<p>In practice, the gradient is used to update the weights in the opposite direction of the steepest ascent to reduce the loss value. This is done by subtracting a fraction (determined by a scaling factor <code>step</code>) of the gradient from the current weight values. This process is based on the idea that moving against the direction of steepest ascent should lead to a lower point on the loss curve. The scaling factor is necessary to ensure that the approximation of curvature provided by the gradient remains accurate by not straying too far from the current point <code>W0</code>.</p>
</div>
<div class="paragraph">
<p>An approach to finding the minimum of a differentiable function analytically by setting its derivative to zero and solving for the function&#8217;s variables. However, this approach is not feasible for neural networks due to the large number of parameters involved.</p>
</div>
<div class="paragraph">
<p>Instead, the text outlines a practical four-step algorithm known as <em>mini-batch stochastic gradient descent</em> (SGD) for optimizing neural networks:</p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>Select a random batch of training samples and corresponding targets.</p>
</li>
<li>
<p>Perform a forward pass to generate predictions from the input samples.</p>
</li>
<li>
<p>Calculate the loss, which measures how well the predictions match the targets.</p>
</li>
<li>
<p>Compute the gradient of the loss with respect to the model parameters and adjust the parameters in the opposite direction of the gradient to reduce the loss.</p>
</li>
</ol>
</div>
<div class="paragraph">
<p>The learning rate is a factor that determines the step size taken when adjusting the parameters. Choosing an appropriate learning rate is important to ensure convergence and avoid being trapped in local minima or making erratic updates.</p>
</div>
<div class="paragraph">
<p>SGD can be performed with individual samples (true SGD) or the entire dataset (batch gradient descent), but mini-batch SGD is a compromise between these methods.</p>
</div>
<div class="paragraph">
<p>Variants of SGD that incorporate previous updates into the current update, such as <em>momentum</em>, which helps to accelerate convergence and avoid local minima. Momentum is likened to a ball rolling down a loss curve, where it uses both the current slope and its existing velocity to move through parameter space.</p>
</div>
<div class="paragraph">
<p><em>Backpropagation</em> is a method for computing the gradient of the loss function of a neural network with respect to its parameters, which are typically the weights and biases. It utilizes the derivatives of simple operations, such as addition, ReLU, or tensor product, which are the building blocks of neural networks. These operations are easily differentiable, allowing for the calculation of gradients in complex networks.</p>
</div>
<div class="paragraph">
<p>A neural network can be represented as a function with parameters like <code>W1</code>, <code>b1</code>, <code>W2</code>, and <code>b2</code>. These parameters are used in operations like <code>dot</code> product, <code>relu</code>, <code>softmax</code>, and addition, combined with a loss function. The chain of operations can be expressed as follows:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="python">loss_value = loss(y_true, softmax(dot(relu(dot(inputs, W1) + b1), W2) + b2))</code></pre>
</div>
</div>
<div class="paragraph">
<p>The chain rule from calculus is employed to derive this function. It states that the gradient of a composed function <code>fg(x) = f(g(x))</code> can be calculated by multiplying the derivatives of the individual functions involved:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="python">grad(y, x) == grad(y, x1) * grad(x1, x)</code></pre>
</div>
</div>
<div class="paragraph">
<p>When more functions are composed together, the chain rule extends like a chain:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="python">grad(y, x) == grad(y, x3) * grad(x3, x2) * grad(x2, x1) * grad(x1, x)</code></pre>
</div>
</div>
<div class="paragraph">
<p>By applying the chain rule to each layer of the network in reverse order (from the output to the input), backpropagation efficiently computes the gradients needed to update the network&#8217;s parameters during training.</p>
</div>
<div class="paragraph">
<p>The <code>GradientTape</code> API in TensorFlow is utilized for automatic differentiation by recording tensor operations within its scope to create a computation graph. Variables, which are mutable tensors, are often used for model parameters. To use the <code>GradientTape</code>:</p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>Create a <code>tf.Variable</code>.</p>
</li>
<li>
<p>Open a <code>tf.GradientTape</code> context.</p>
</li>
<li>
<p>Perform tensor computations inside this context.</p>
</li>
<li>
<p>Calculate gradients of an output with respect to variables using <code>tape.gradient()</code>.</p>
</li>
</ol>
</div>
<div class="paragraph">
<p>The <code>GradientTape</code> can handle various tensor operations and can work with both single variables and lists of variables. For example, it can be used to calculate the gradient of a simple linear equation, or more complex operations like a matrix multiplication followed by an addition. The resulting gradients will have the same shape as the variables they are derived from.</p>
</div>
</div>
<div class="sect2">
<h3 id="_2_5_looking_back_at_our_first_example">2.5 Looking back at our first example</h3>
<div class="paragraph">
<p>A model is described as a series of layers that transform input data into predictions. These predictions are then evaluated by a loss function against the expected outcomes, producing a loss value that indicates the model&#8217;s performance. An optimizer uses this loss value to adjust the model’s weights.</p>
</div>
<div class="paragraph">
<p>The author revisits the first example from the chapter, explaining the process step by step. First, the input data is preprocessed and formatted into a specific shape and data type suitable for the model. The model itself is a sequential composition of two dense layers, each performing operations on the input data with weight tensors, which are essentially the learned parameters of the model.</p>
</div>
<div class="paragraph">
<p>The model compilation step involves defining the loss function and optimizer. The loss function used here is <code>sparse_categorical_crossentropy</code>, providing a signal to guide the learning process by minimizing loss. The <code>rmsprop</code> optimizer sets the specific rules for the gradient descent process during training.</p>
</div>
<div class="paragraph">
<p>Finally, the training loop is discussed, illustrating how the model iterates over the training data in mini-batches, updating the model weights in each epoch through backpropagation. After several epochs, the model&#8217;s loss decreases, and its accuracy in classifying handwritten digits improves.</p>
</div>
<div class="paragraph">
<p>The implementation of a simple Python class <code>NaiveDense</code> which simulates a dense (fully connected) layer in a neural network using TensorFlow. The class is initialized with an input size, an output size, and an activation function. It creates two TensorFlow variables: <code>W</code> (weights matrix) and <code>b</code> (biases vector). The weights are initialized with random values within a specified range, while the biases are initialized with zeros.</p>
</div>
<div class="paragraph">
<p>The class defines a <code><em>call</em></code> method that performs the forward pass by computing the dot product of the inputs and weights, adding the biases, and then applying the activation function to the result.</p>
</div>
<div class="paragraph">
<p>Additionally, the class includes a <code>weights</code> property that provides convenient access to the layer&#8217;s parameters (weights and biases).</p>
</div>
<div class="paragraph">
<p><code>NaiveSequential</code> class is used to create a neural network by chaining together multiple layers. The class takes a list of layers as an argument and sequentially applies each layer to the input data. The <code><em>call</em>()</code> method is used to process the inputs through the layers in the order they were added. The class also includes a <code>weights</code> property that aggregates all the parameters from the individual layers.</p>
</div>
<div class="paragraph">
<p>Following the description, an example usage of the <code>NaiveSequential</code> class is given, where a simple neural network model is created with two layers: a <code>NaiveDense</code> layer with ReLU activation followed by another <code>NaiveDense</code> layer with softmax activation. The model is expected to have four sets of weights, indicating that each <code>NaiveDense</code> layer has both weights and biases.</p>
</div>
<div class="paragraph">
<p>The steps involved in the training process of a machine learning model and code snippets for implementing these steps using TensorFlow. The main steps in the training process are:</p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>Run the model on a batch of images to generate predictions.</p>
</li>
<li>
<p>Calculate the loss using the model&#8217;s predictions and the actual labels.</p>
</li>
<li>
<p>Compute the gradient of the loss with respect to the model&#8217;s weights.</p>
</li>
<li>
<p>Adjust the weights slightly in the opposite direction of the gradient to minimize loss.</p>
</li>
</ol>
</div>
<div class="paragraph">
<p>The code uses TensorFlow&#8217;s <code>GradientTape</code> to record operations for automatic differentiation. Within the <code>one_training_step</code> function, a forward pass is performed to compute predictions and loss, and then the gradient is calculated. This gradient is used by the <code>update_weights</code> function to adjust the model weights, with a defined learning rate as a scaling factor.</p>
</div>
<div class="paragraph">
<p>Two approaches for the weight update step are provided: a manual approach that directly modifies the weights using <code>assign_sub</code>, and a more practical approach that employs Keras' <code>Optimizer</code> class, specifically the <code>SGD</code> (Stochastic Gradient Descent) optimizer, to handle the weight adjustment.</p>
</div>
<div class="paragraph">
<p>These steps are part of the training loop, which iterates over the training data for multiple epochs to improve the model&#8217;s performance.</p>
</div>
</div>
<div class="sect2">
<h3 id="_summary">Summary</h3>
<div class="ulist">
<ul>
<li>
<p><em>Tensors</em> form the foundation of modern machine learning systems. They come in various flavors of <code>dtype</code>, <code>rank</code>, and <code>shape</code>.</p>
</li>
<li>
<p>You can manipulate numerical tensors via <em>tensor operations</em> (such as addition, tensor product, or element-wise multiplication), which can be interpreted as encoding geometric transformations. In general, everything in deep learning is amenable to a geometric interpretation.</p>
</li>
<li>
<p>Deep learning models consist of chains of simple tensor operations, parameterized by <em>weights</em>, which are themselves tensors. The weights of a model are where its “knowledge” is stored.</p>
</li>
<li>
<p><em>Learning</em> means finding a set of values for the model’s weights that minimizes a <em>loss function</em> for a given set of training data samples and their corresponding targets.</p>
</li>
<li>
<p>Learning happens by drawing random batches of data samples and their targets, and computing the gradient of the model parameters with respect to the loss on the batch. The model parameters are then moved a bit (the magnitude of the move is defined by the learning rate) in the opposite direction from the gradient. This is called <em>mini-batch stochastic gradient descent</em>.</p>
</li>
<li>
<p>The entire learning process is made possible by the fact that all tensor operations in neural networks are differentiable, and thus it’s possible to apply the chain rule of derivation to find the gradient function mapping the current parameters and current batch of data to a gradient value. This is called <em>backpropagation</em>.</p>
</li>
<li>
<p>Two key concepts you’ll see frequently in future chapters are <em>loss</em> and <em>optimizers</em>. These are the two things you need to define before you begin feeding data into a model.</p>
</li>
<li>
<p>The <em>loss</em> is the quantity you’ll attempt to minimize during training, so it should represent a measure of success for the task you’re trying to solve.</p>
</li>
<li>
<p>The <em>optimizer</em> specifies the exact way in which the gradient of the loss will be used to update parameters: for instance, it could be the RMSProp optimizer, SGD with momentum, and so on.</p>
</li>
</ul>
</div>
</div>
</div>
</div>
</div>
<div id="footer">
<div id="footer-text">
Last updated 2023-12-25 12:48:34 +0200
</div>
</div>
</body>
</html>