= LangChain Docs
:source-highlighter: coderay
:toc:

== Capabilities

=== Embeddings

==== Overview

> https://platform.openai.com/docs/guides/embeddings/what-are-embeddings

OpenAI's text embeddings are used to measure the relatedness of text strings, facilitating applications like search, clustering, recommendations, anomaly detection, diversity measurement, and classification. The Assistants API now includes retrieval and message history management. An embedding is a numerical vector where distances between vectors indicate the level of relatedness.

To obtain embeddings, you send text to the embeddings API endpoint using a specific model ID, such as `text-embedding-ada-002`, and receive a vector in response. OpenAI offers a second-generation and several first-generation embedding models, with `text-embedding-ada-002` recommended for most uses.

Embeddings can be applied in several use cases, such as data visualization, machine learning models for regression and classification, zero-shot classification, user and product embeddings for recommendations, clustering, and text and code search.

However, the models have limitations, including encoding social biases and lacking knowledge of events after August 2020. Users should be aware of these limitations and the social risks involved in their applications. OpenAI also provides guidance on counting tokens, retrieving nearest embedding vectors using vector databases, and recommends cosine similarity as the preferred distance function. Customers own their input and output data, but must ensure compliance with applicable laws and OpenAI's Terms of Use.

== Assistants

=== Overview

> https://platform.openai.com/docs/assistants/overview

The Assistants API by OpenAI allows users to create AI assistants within applications. These assistants can use various tools such as `Code Interpreter`, `Retrieval`, and `Function calling` to respond to user queries. The API is currently in beta, but it supports a range of functionalities, including the ability to create personalized Assistants and manage conversations through Threads and Messages. Users can also control the flow of the conversation and the assistant's responses by providing specific instructions and enabling tools.

The integration process involves several steps:

1. Creating an Assistant with custom instructions and model choice, and enabling desired tools.
2. Initiating a Thread to represent a user's conversation.
3. Adding Messages to the Thread as the conversation progresses.
4. Running the Assistant to generate responses, which may involve calling enabled tools.

The Assistants API also features a playground for users to experiment with building Assistants without coding. The process in the playground involves setting up an Assistant, creating a Thread, adding Messages, running the Assistant, and finally, displaying the Assistant's responses to the user.

The API handles the complexity of managing the conversation context, optimizing the input for the model, and controlling costs. Future updates, including support for new tools and user-provided tools, are expected. Users are encouraged to provide feedback in the OpenAI Developer Forum, and developers can use OpenAI's official SDKs to facilitate API calls.
